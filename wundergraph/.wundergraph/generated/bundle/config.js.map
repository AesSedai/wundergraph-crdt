{
  "version": 3,
  "sources": ["../../lib/pigeon/helpers.js", "../../lib/pigeon/diff.js", "../../lib/pigeon/patch.js", "../../lib/pigeon/reverse.js", "../../lib/pigeon/auto.js", "../../lib/pigeon/index.js", "../../wundergraph.config.ts", "../../wundergraph.operations.ts", "../../wundergraph.server.ts", "../../lib/y-pojo/y-pojo.ts", "../../lib/yjs/src/utils/DeleteSet.js", "../../lib/yjs/src/utils/encoding.js", "../../lib/yjs/src/utils/StructStore.js", "../../lib/yjs/src/utils/Transaction.js"],
  "sourcesContent": ["let _config = {\n  strict: true,\n  getObjectId: x => x.id || x._id || x.uuid || x.slug,\n  getTimestamp: Date.now,\n};\n\nfunction _configure(options) {\n  Object.assign(_config, options);\n}\n\nfunction _path(path, k, o) {\n  if (o) {\n    const id = _objId(o);\n    if (id) k = `[${id}]`;\n  }\n  return _encodePath(path, k);\n}\n\nfunction _encodeKey(key) {\n  return typeof(key) == 'string' && (key.indexOf('/') !== -1 || key.indexOf('~') !== -1) ?\n    key.replace(/~/g, '~0').replace(/\\//g, '~1') :\n    key;\n}\n\nfunction _decodeKey(key) {\n  return typeof(key) == 'string' && (key.indexOf('~1') !== -1 || key.indexOf('~0') !== -1) ?\n    key.replace(/~1/g, '/').replace(/~0/g, '~') :\n    key;\n}\n\nfunction _decodePath(path) {\n  return path.split('/').map(c => _decodeKey(c))\n}\n\nfunction _encodePath(path, k) {\n  k = _encodeKey(k);\n  return [path, k].filter(x => x != undefined).join('/').replace('//', '/');\n}\n\nfunction _typeof(x) {\n  if (Array.isArray(x)) return 'array';\n  if (x === null) return 'null';\n  return typeof x;\n}\n\nfunction _isPrimitive(x) {\n  const t = _typeof(x);\n  return t === 'number' || t === 'null' || t === 'boolean' || t == 'string';\n}\n\nfunction _clone(x) {\n  const type = _typeof(x);\n  if (type == 'array') {\n    const arr = Array(x.length);\n    for (let i = 0; i < x.length; i++) {\n      arr[i] = _clone(x[i]);\n    }\n    return arr;\n  } else if (type == 'object') {\n    if (x.toJSON) {\n      return x.toJSON();\n    } else {\n      const obj = {};\n      for (const k in x) {\n        obj[k] = _clone(x[k]);\n      }\n      return obj;\n    }\n  } else if (_isPrimitive(x)) {\n    const isNumber = typeof x == 'number';\n    if (isNumber) {\n      if (isFinite(x)) {\n        return x;\n      } else {\n        return null;\n      }\n    } else {\n      return x;\n    }\n  }\n}\n\nfunction _entangled(a, b) {\n  if (_isPrimitive(a)) {\n    return a === b;\n  } else if (_typeof(a) == 'object') {\n    return _objId(a) === _objId(b);\n  } else if (_typeof(a) == 'array') {\n    throw new Error(\"can't compare arrays of arrays\");\n  }\n}\n\nfunction _objId(x) {\n  if (_typeof(x) == 'object') {\n    const id = _config.getObjectId(x);\n    if (id != undefined) return id;\n    if (_config.strict) {\n      throw new Error(\"couldn't find id for object\", { cause: x });\n    }\n    return _hsh(_stable(x));\n  } else {\n    return null;\n  }\n}\n\nfunction _op(op, path, extra) {\n  const operation = { op, path };\n  Object.assign(operation, extra);\n  return operation;\n}\n\nfunction _stable(x) {\n  if (_typeof(x) == 'array') {\n    return `[${x.map(_stable).join(',')}]`;\n  } else if (_typeof(x) == 'object') {\n    return `{${Object.keys(x).sort().map(k =>\n      `${JSON.stringify(k)}:${_stable(x[k])}`).join(',')}}`;\n  } else {\n    return JSON.stringify(x);\n  }\n}\n\nfunction _hsh(str) {\n  return Math.abs([].reduce.call(str, (p, c, i, a) => (p << 5) - p + a.charCodeAt(i), 0));\n}\n\nfunction _crc(x) {\n  return _hsh(_stable(x));\n}\n\nmodule.exports = {\n  _path,\n  _typeof,\n  _isPrimitive,\n  _clone,\n  _entangled,\n  _objId,\n  _op,\n  _stable,\n  _crc,\n  _decodePath,\n  _config,\n  _configure,\n}\n", "const { _path, _typeof, _isPrimitive, _clone, _entangled, _objId, _op, _config } = require('./helpers');\n\n\nfunction diff(left, right) {\n\n  const type = _typeof(left);\n\n  if (type !== _typeof(right)) {\n    throw new Error(\"can't diff different types\");\n  }\n\n  if (type == 'array') {\n    return diffArray(left, right);\n  } else if (type == 'object') {\n    return diffObject(left, right);\n  } else if (_isPrimitive(left)) {\n    return diffPrimitive(left, right);\n  } else {\n    throw new Error(\"unsupported type\");\n  }\n\n}\n\nfunction diffPrimitive(l, r, path='/') {\n  if (l !== r) {\n    return [_op('replace', _path(path), { value: r,  _prev: l, })];\n  } else {\n    return [];\n  }\n}\n\nfunction diffArray(l, r, path='/') {\n\n  const lris = {};\n  const rlis = {};\n\n  const adds = [];\n\n  for (let i = 0; i < l.length; i++) {\n    for (let j = 0; j < r.length; j++) {\n      if (j in rlis) continue;\n      if (i in lris) continue;\n      if (\n        (!_config.strict && _typeof(l[i]) == 'array' && _typeof(r[j]) == 'array' && i == j) ||\n        _entangled(l[i], r[j])\n      ) {\n        lris[i] = j;\n        rlis[j] = i;\n      }\n    }\n  }\n\n  const ops = [];\n\n  for (let i = 0, j = 0; j < r.length || i < l.length;) {\n\n    if (j in r && i in l && rlis[j] == i) {\n\n      if (_typeof(r[j]) === 'object') {\n        ops.push(...diffObject(l[i], r[j], _path(path, i, r[j])));\n      }\n      j++;\n      i++;\n      continue;\n    }\n\n    if (i < l.length && !(i in lris)) {\n      ops.push(_op('remove', _path(path, i, l[i]), { _prev: l[i] }));\n      i++;\n      continue;\n    }\n\n    if (j < r.length && !(j in rlis)) {\n      adds.unshift(_op('add', _path(path, j, r[j + 1]), { value: r[j] }));\n      j++;\n      continue;\n    }\n\n    if (j < r.length && j in rlis) {\n      const from = _path(path, rlis[j], l[rlis[j]]);\n      const to = _path(path, j);\n      if (to != from) {\n        ops.push({ op: 'move', from, path: to });\n        if (_typeof(rlis[j]) == 'object') {\n          ops.push(...diffObject(l[rlis[j]], r[j], path));\n        }\n      }\n      i++;\n      j++;\n      continue;\n    }\n\n    throw new Error(`couldn't create diff`);\n  }\n\n  return ops.concat(adds);\n}\n\n\nfunction diffObject(l, r, path='/', ref) {\n\n  const ops = [];\n\n  const lkeys = Object.keys(l);\n  const llen = lkeys.length;\n  let removals = 0;\n\n  for (let i = 0; i < llen; i++){\n\n    const k = lkeys[i];\n    if (!(r.hasOwnProperty(k))) {\n      removals++;\n      ops.push({ op: 'remove', path: _path(path, k), _prev: _clone(l[k]) });\n      continue;\n    }\n\n    if (l[k] === r[k]) continue;\n\n    const type = _typeof(l[k]);\n\n    if (_isPrimitive(l[k])) {\n      ops.push(...diffPrimitive(l[k], r[k], _path(path, k), ref));\n    } else if (type !== _typeof(r[k])) {\n      ops.push({ op: 'replace', path: _path(path, k), value: _clone(r[k]), _prev: _clone(l[k]) });\n    } else if (type === 'array') {\n      ops.push(...diffArray(l[k], r[k], _path(path, k)));\n    } else if (type === 'object') {\n      ops.push(...diffObject(l[k], r[k], _path(path, k), ref));\n    }\n  }\n\n  const rkeys = Object.keys(r);\n  const rlen = rkeys.length;\n\n  if (rlen > llen - removals) {\n    for (let i = 0; i < rlen; i++) {\n      const k = rkeys[i];\n      if (!(l.hasOwnProperty(k))) {\n        ops.push({ op: 'add', path: _path(path, k), value: _clone(r[k]) });\n      }\n    }\n  }\n\n  return ops\n}\n\n\nmodule.exports = diff;\n", "const { _typeof, _clone, _objId, _decodePath } = require('./helpers');\n\n\nfunction patch(data, changes) {\n\n  changes = _clone(changes);\n  const conflicts = [];\n  let stash = null;\n\n  CHANGE:\n  for (const [ci, change] of changes.entries()) {\n\n    const components = _decodePath(change.path);\n    const root = components.shift();\n    let tip = components.pop();\n\n    let head = data;\n\n    for (const c of components) {\n      if (!head) {\n        conflicts.push(change);\n        continue CHANGE;\n      }\n      const key = _key(c);\n      if (key) {\n        head = head.find(i => _objId(i) == key);\n      } else {\n        head = head[c];\n      }\n    }\n\n    const key = _key(tip);\n    if (key) {\n      const idx = head.findIndex(i => _objId(i) == key);\n      if (~idx) {\n        tip = idx;\n      } else {\n        conflicts.push(change);\n      }\n    }\n\n    const type = _typeof(head);\n\n    if (change.op == 'replace') {\n      head[tip] = _clone(change.value);\n    } else if (change.op == 'move') {\n      stash = {};\n      const ops = [\n        { op: 'remove', path: change.from },\n        { op: 'add', path: change.path, value: stash }\n      ];\n      changes.splice(ci + 1, 0, ...ops);\n    } else if (change.op == 'remove') {\n      if (type == 'object') {\n        stash && (stash.value = _clone(head[tip]));\n        delete head[tip];\n      } else if (type == 'array') {\n        const value = head.splice(tip, 1);\n        stash && ([ stash.value ] = value);\n      }\n    } else if (change.op == 'add') {\n      if (type == 'object') {\n        head[tip] = _clone(change.value);\n      } else if (type == 'array') {\n        if (stash && change.value === stash) {\n          head.splice(tip, 0, stash.value);\n          stash = null;\n        } else {\n          head.splice(tip, 0, _clone(change.value));\n        }\n      }\n    }\n  }\n  return data;\n}\n\n\nfunction _key(c) {\n  if (c === undefined) return;\n  const m = c.match(/^\\[(.+)\\]$/);\n  if (m) return m[1];\n}\n\nmodule.exports = patch;\n", "const { _clone, _objId } = require('./helpers');\n\nfunction reverse(changes) {\n\n  const reversed = _clone(changes).reverse();\n\n  for (const change of reversed) {\n\n    if (change.op == 'add') {\n      change.op = 'remove';\n      const id = _objId(change.value);\n      if (id) {\n        change._index = change.path.split('/').pop();\n        change.path = change.path.replace(/\\d+$/, `[${id}]`);\n      }\n\n    } else if (change.op == 'remove') {\n      change.op = 'add';\n    }\n\n    if ('_prev' in change) {\n      var _prev = change._prev;\n    }\n\n    if ('value' in change) {\n      var _value = change.value;\n    }\n\n    if (_prev === undefined) {\n      delete change.value;\n    } else {\n      change.value = _prev;\n    }\n\n    if (_value === undefined) {\n      delete change._prev;\n    } else {\n      change._prev = _value;\n    }\n\n  }\n\n  return reversed;\n\n}\n\nmodule.exports = reverse;\n", "const assert = require('assert');\nconst diff = require('./diff');\nconst patch = require('./patch');\nconst reverse = require('./reverse');\nconst { _clone, _crc, _configure, _config } = require('./helpers');\n\nlet HISTORY_LENGTH = 1000;\n\nconst meta = new WeakMap();\nconst _cid = _id();\n\nclass AutoPigeon {\n\n  constructor() {\n    meta.set(this, {\n      history: [],\n      stash: [],\n      warning: null,\n      gids: {},\n    });\n  }\n\n  static from(data, cid=_cid) {\n    let doc = new AutoPigeon();\n    meta.get(doc).cid = cid;\n    doc = AutoPigeon.change(doc, doc => Object.assign(doc, data));\n    return doc;\n  }\n\n  static _forge(data, cid=_cid) {\n    let doc = new AutoPigeon();\n    meta.get(doc).cid = cid;\n    Object.assign(doc, _clone(data));\n    return doc;\n  }\n\n  static alias(doc) {\n    let alias = new AutoPigeon();\n    meta.set(alias, meta.get(doc));\n    Object.assign(alias, doc);\n    return alias;\n  }\n\n  static init() {\n    return AutoPigeon.from({});\n  }\n\n  static clone(doc, historyLength=HISTORY_LENGTH) {\n    const clone = AutoPigeon._forge(doc);\n    meta.get(clone).history = meta.get(doc).history;\n    meta.get(clone).gids = _clone(meta.get(doc).gids);\n    AutoPigeon.pruneHistory(meta.get(clone), historyLength)\n    return clone;\n  }\n\n  static pruneHistory(meta, historyLength) {\n    const docHistoryLength = meta.history.length;\n    if (docHistoryLength > historyLength) {\n      const prunedHistory = meta.history.slice(0, docHistoryLength - historyLength);\n      for (const item of prunedHistory) {\n        delete meta.gids[item.gid];\n      }\n    }\n    meta.history = meta.history.slice(-historyLength);\n  }\n\n  static getChanges(left, right) {\n    const _diff = diff(left, right);\n    const changes = {\n      diff: _diff,\n      cid: meta.get(left).cid,\n      ts: _config.getTimestamp(),\n      seq: _seq(),\n      gid: _id(),\n    }\n    return changes;\n  }\n\n  static rewindChanges(doc, ts, cid) {\n\n    const { history } = meta.get(doc);\n\n    while (true) {\n      if (history.length <= 1) break;\n      const change = history[history.length - 1];\n      if (change.ts > ts || (change.ts == ts && change.cid > cid)) {\n        const c = meta.get(doc).history.pop();\n        patch(doc, reverse(c.diff));\n        delete meta.get(doc).gids[c.gid];\n        meta.get(doc).stash.push(c);\n        continue;\n      }\n      break;\n    }\n  }\n\n  static fastForwardChanges(doc) {\n    const { stash, history } = meta.get(doc);\n    let change;\n    while (change = stash.pop()) {\n      patch(doc, change.diff);\n      meta.get(doc).gids[change.gid] = 1;\n      history.push(change);\n    }\n  }\n\n  static applyChangesInPlace(doc, changes) {\n    return AutoPigeon.applyChanges(doc, changes, true);\n  }\n\n  static applyChanges(doc, changes, inplace) {\n    meta.get(doc).warning = null;\n    const newDoc = inplace ? doc : AutoPigeon.clone(doc);\n    if (meta.get(doc).gids[changes.gid]) {\n      return newDoc;\n    }\n    try {\n      AutoPigeon.rewindChanges(newDoc, changes.ts, changes.cid);\n    } catch (e) {\n      meta.get(newDoc).warning = 'rewind failed: ' + e;\n    }\n    try {\n      patch(newDoc, changes.diff);\n      meta.get(newDoc).gids[changes.gid] = 1;\n    } catch (e) {\n      meta.get(newDoc).warning = 'patch failed: ' + e;\n    }\n    try {\n      AutoPigeon.fastForwardChanges(newDoc);\n    } catch (e) {\n      meta.get(newDoc).warning = 'forward failed: ' + e;\n    }\n    const history = meta.get(newDoc).history;\n    let idx = history.length;\n    while (idx > 1 && history[idx - 1].ts > changes.ts) idx--;\n    history.splice(idx, 0, changes);\n    return newDoc;\n  }\n\n  static change(doc, fn) {\n\n    assert(doc instanceof AutoPigeon);\n    assert(fn instanceof Function);\n\n    const tmp = _clone(doc);\n    fn(tmp);\n    const changes = AutoPigeon.getChanges(doc, tmp);\n    return AutoPigeon.applyChanges(doc, changes);\n  }\n\n  static getHistory(doc) {\n    return meta.get(doc).history;\n  }\n\n  static merge(doc1, doc2) {\n    let doc = AutoPigeon.from({});\n    const history1 = AutoPigeon.getHistory(doc1);\n    const history2 = AutoPigeon.getHistory(doc2);\n    const changes = [];\n    while (history1.length || history2.length) {\n      if (!history2.length) {\n        changes.push(history1.shift());\n\n      } else if (!history1.length) {\n        changes.push(history2.shift());\n\n      } else if (history1[0].gid === history2[0].gid) {\n        changes.push(history1.shift() && history2.shift());\n\n      } else if (history1[0].ts < history2[0].ts) {\n        changes.push(history1.shift());\n\n      } else if (history1[0].ts == history2[0].ts) {\n\n        if (history1[0].seq < history2[0].seq) {\n          changes.push(history1.shift());\n        } else {\n          changes.push(history2.shift());\n        }\n\n      } else {\n        changes.push(history2.shift());\n      }\n    }\n\n    for (const c of changes) {\n      doc = AutoPigeon.applyChanges(doc, c);\n    }\n    return doc;\n  }\n\n  static getWarning(doc) {\n    return meta.get(doc).warning;\n  }\n\n  static getMissingDeps(doc) {\n    return false;\n  }\n\n  static setHistoryLength(len) {\n    HISTORY_LENGTH = len;\n  }\n\n  static setTimestamp(fn) {\n    _config.getTimestamp = fn;\n  }\n\n  static crc(doc) {\n    return _crc(doc);\n  }\n\n  static load(str, historyLength=HISTORY_LENGTH) {\n    const { meta: _meta, data } = JSON.parse(str);\n    AutoPigeon.pruneHistory(_meta, historyLength);\n    const doc = AutoPigeon.from(data);\n    Object.assign(meta.get(doc), _meta);\n    return doc;\n  }\n\n  static save(doc) {\n    const { cid, ..._meta } = meta.get(doc);\n    return JSON.stringify({\n      meta: _meta,\n      data: doc,\n    });\n  }\n\n  static configure(options) {\n    _configure(options);\n  }\n}\n\nfunction _id() {\n  return Math.random().toString(36).substring(2);\n}\n\nlet seq = 0;\nfunction _seq() {\n  return seq++;\n}\n\nmodule.exports = AutoPigeon;\n", "const diff = require('./diff');\nconst patch = require('./patch');\nconst reverse = require('./reverse');\nconst auto = require('./auto');\n\nfunction configure(options) {\n  helpers._configure(options);\n}\n\nmodule.exports = Object.assign(auto, { auto, diff, patch, reverse });\n", "import { configureWunderGraphApplication, cors, EnvironmentVariable, introspect, templates } from \"@wundergraph/sdk\"\r\nimport operations from \"./wundergraph.operations\"\r\nimport server from \"./wundergraph.server\"\r\n\r\nconst hasura = introspect.graphql({\r\n    apiNamespace: \"hasura\",\r\n    url: new EnvironmentVariable(\"HASURA_GRAPHQL_HTTP_URL\"),\r\n    headers: (builder) =>\r\n        builder.addStaticHeader(\"x-hasura-admin-secret\", new EnvironmentVariable(\"HASURA_GRAPHQL_ADMIN_SECRET\"))\r\n})\r\n\r\n// configureWunderGraph emits the configuration\r\nconfigureWunderGraphApplication({\r\n    apis: [hasura],\r\n    server,\r\n    operations,\r\n    codeGenerators: [\r\n        {\r\n            templates: [...templates.typescript.all]\r\n        },\r\n        {\r\n            templates: [templates.typescript.client],\r\n            path: \"../../client/src/graphql\"\r\n        }\r\n    ],\r\n    cors: {\r\n        ...cors.allowAll,\r\n        allowedOrigins: [\"*\"]\r\n        // allowedOrigins: [new EnvironmentVariable(\"CLIENT_HOST_URL\"), \"http://127.0.0.1:5000\", \"http://127.0.0.1:3000\", \"http://wg.local\", \"https://wg.local\"]\r\n    },\r\n    dotGraphQLConfig: {\r\n        hasDotWunderGraphDirectory: false\r\n    },\r\n    security: {\r\n        enableGraphQLEndpoint: true //process.env.NODE_ENV !== 'production' || process.env.GITPOD_WORKSPACE_ID !== undefined,\r\n    }\r\n})\r\n", "import { configureWunderGraphOperations } from \"@wundergraph/sdk\"\r\nimport type { OperationsConfiguration } from \"./generated/wundergraph.operations\"\r\n\r\nexport default configureWunderGraphOperations<OperationsConfiguration>({\r\n    operations: {\r\n        defaultConfig: {\r\n            authentication: {\r\n                required: false\r\n            }\r\n        },\r\n        queries: (config) => ({\r\n            ...config,\r\n            caching: {\r\n                enable: false,\r\n                staleWhileRevalidate: 60,\r\n                maxAge: 60,\r\n                public: true\r\n            },\r\n            liveQuery: {\r\n                enable: true,\r\n                pollingIntervalSeconds: 1\r\n            }\r\n        }),\r\n        mutations: (config) => ({\r\n            ...config\r\n        }),\r\n        subscriptions: (config) => ({\r\n            ...config\r\n        }),\r\n        custom: {}\r\n    }\r\n})\r\n", "import { configureWunderGraphServer } from \"@wundergraph/sdk/server\"\r\nimport { GraphQLObjectType, GraphQLSchema, GraphQLString } from \"graphql\"\r\nimport { fromUint8Array, toUint8Array } from \"js-base64\"\r\nimport * as Y from \"yjs\"\r\n// import { CrdtAuthorsResponse } from \"./generated/models\"\r\nimport type { HooksConfig } from \"./generated/wundergraph.hooks\"\r\nimport type { InternalClient } from \"./generated/wundergraph.internal.client\"\r\nimport type { GraphQLExecutionContext } from \"./generated/wundergraph.server\"\r\nimport { syncronize } from \"./lib/y-pojo/y-pojo\"\r\nconst { diff: pDiff } = require(\"./lib/pigeon\")\r\nimport { cloneDeep } from \"lodash\"\r\nimport { writeUpdateMessageFromTransaction } from \"./lib/yjs/src/utils/Transaction.js\"\r\n\r\nconst docMap = new Map<string, Y.Doc>()\r\nconst roomName = \"authors\"\r\n\r\nexport default configureWunderGraphServer<HooksConfig, InternalClient>(() => ({\r\n    hooks: {\r\n        queries: {},\r\n        mutations: {\r\n            ResetAuthors: {\r\n                postResolve: async () => {\r\n                    // set initialSync back to true\r\n                    // initialSync = true\r\n                }\r\n            }\r\n        },\r\n        subscriptions: {\r\n            CrdtAuthors: {\r\n                mutatingPreResolve: async ({ input, user, log, internalClient, clientRequest }) => {\r\n                    console.log(`preResolve hook called for CrdtAuthors with ${JSON.stringify(input, null, 2)}`)\r\n\r\n                    let { data } = await internalClient.queries.QueryCrdt({ input: { room: roomName } })\r\n                    let response = data?.hasura_crdt?.[0]\r\n\r\n                    // populate docMap if required\r\n                    if (!docMap.has(roomName)) {\r\n                        let ydoc1: Y.Doc\r\n\r\n                        if (response == null) {\r\n                            // initialize new document\r\n                            ydoc1 = new Y.Doc()\r\n                            const ymap1 = ydoc1.getMap(\"data\")\r\n                            const { data } = await internalClient.mutations.CreateCrdt({\r\n                                input: {\r\n                                    crdt: {\r\n                                        room: roomName,\r\n                                        client: ydoc1.clientID.toString(),\r\n                                        guid: ydoc1.guid,\r\n                                        state: fromUint8Array(Y.encodeStateAsUpdate(ydoc1)),\r\n                                        vector: fromUint8Array(Y.encodeStateVector(ydoc1))\r\n                                    }\r\n                                }\r\n                            })\r\n                            const result = data?.hasura_insert_crdt_one\r\n                            if (result != null) {\r\n                                response = result\r\n                            }\r\n                        } else {\r\n                            // hydrate document\r\n                            ydoc1 = new Y.Doc({ guid: response.guid })\r\n                            ydoc1.clientID = parseInt(response.client)\r\n                            const ymap1 = ydoc1.getMap(\"data\")\r\n                            Y.applyUpdate(ydoc1, toUint8Array(response.state))\r\n                            ydoc1.clientID = parseInt(response.client)\r\n                        }\r\n\r\n                        docMap.set(roomName, ydoc1)\r\n\r\n                        ydoc1.on(\"update\", (update, origin, doc, transaction) => {\r\n                            console.log(\"received updated for doc from origin\", origin, \"update\", fromUint8Array(update))\r\n                            // Y.logUpdate(update)\r\n                        })\r\n                    }\r\n\r\n                    if (response != null) {\r\n                        // populate client if required\r\n                        const clientResponse = await internalClient.mutations.UpsertClient({\r\n                            input: {\r\n                                client: {\r\n                                    crdt_id: response.id,\r\n                                    client: input.clientId,\r\n                                    guid: input.guid,\r\n                                    vector: input.sv\r\n                                }\r\n                            }\r\n                        })\r\n                    }\r\n\r\n                    return input\r\n                },\r\n                mutatingPostResolve: async ({ input, user, clientRequest, log, response, internalClient }) => {\r\n                    console.log(\r\n                        `mutatingPostResolve hook called for CrdtAuthors with ${JSON.stringify(input, null, 2)}`\r\n                    )\r\n                    if (response.data == null) {\r\n                        throw new Error(\"response data cannot be null\")\r\n                    }\r\n\r\n                    const ydoc1 = docMap.get(roomName)\r\n                    if (ydoc1 == null) {\r\n                        throw new Error(\"mutatingPostResolve: ydoc1 should be in the docMap\")\r\n                    }\r\n                    const yDataMap = ydoc1.getMap(\"data\")\r\n\r\n                    console.log(\"mutatingPostResolve: querying client\")\r\n                    const qResponse = await internalClient.queries.QueryClient({\r\n                        input: { client: input.clientId, room: roomName }\r\n                    })\r\n                    console.log(\"qResponse\", qResponse)\r\n\r\n                    const client = qResponse?.data?.hasura_clients[0]\r\n                    console.log(\"mutatingPostResolve client\", client)\r\n                    if (client == null) {\r\n                        throw new Error(\"client cannot be null\")\r\n                    }\r\n\r\n                    let diff: Uint8Array\r\n\r\n                    const pDiffStart = process.hrtime()\r\n                    const pDiffContent = pDiff(yDataMap.toJSON(), response.data)\r\n                    const pDiffEnd = process.hrtime(pDiffStart)\r\n                    console.log(\"pDiff time\",  pDiffEnd[1] / 1000000, \"changes\", JSON.stringify(pDiffContent, null, 2))\r\n                    console.log(\"synchronizing from vector\", client.vector)\r\n\r\n                    const syncDiffStart = process.hrtime()\r\n                    let t: Y.Transaction | null = null\r\n\r\n                    ydoc1.transact((tx) => {\r\n                        syncronize(yDataMap, response!.data!)\r\n                        t = cloneDeep(tx)\r\n                    })\r\n\r\n                    if (t == null) {\r\n                        throw new Error(\"t cannot be null\")\r\n                    }\r\n\r\n                    const encoder = new Y.UpdateEncoderV1()\r\n                    const hasContent = writeUpdateMessageFromTransaction(encoder, t)\r\n                    console.log(\"update has content\", hasContent, fromUint8Array(encoder.toUint8Array()))\r\n\r\n                    const syncDiffEnd = process.hrtime(syncDiffStart)\r\n\r\n                    if (!hasContent) {\r\n                        // quick return\r\n                        return { data: {} } as unknown as any\r\n                    }\r\n\r\n                    diff = Y.encodeStateAsUpdate(ydoc1, toUint8Array(client.vector))\r\n                    console.log(\"syncrhonized, got diff in\", syncDiffEnd[1] / 1000000, \"upserting CRDT result\", ydoc1.clientID.toString())\r\n\r\n                    const crdtResponse = await internalClient.mutations.UpsertCrdt({\r\n                        input: {\r\n                            client: ydoc1.clientID.toString(),\r\n                            crdt: {\r\n                                state: fromUint8Array(Y.encodeStateAsUpdate(ydoc1)),\r\n                                vector: fromUint8Array(Y.encodeStateVector(ydoc1))\r\n                            }\r\n                        }\r\n                    })\r\n\r\n                    // console.log(\"mutatingPostResolve success, crdtResponse\", crdtResponse)\r\n\r\n                    // const diffUpdate = Y.diffUpdate(diff, toUint8Array(client.vector))\r\n                    // console.log(\"diffUpdate\", fromUint8Array(diffUpdate))\r\n                    // const esvDiff = Y.encodeStateVectorFromUpdate(diffUpdate)\r\n                    // console.log(\"diffUpdate sv\", fromUint8Array(esvDiff))\r\n\r\n                    // console.log(\"mutatingPostResolve upserting client\")\r\n                    const clientResponse = await internalClient.mutations.UpsertClient({\r\n                        input: {\r\n                            client: {\r\n                                client: input.clientId,\r\n                                guid: input.guid,\r\n                                vector: fromUint8Array(Y.encodeStateVector(ydoc1)) // fromUint8Array(esvDiff) // fromUint8Array(Y.encodeStateVectorFromUpdate(diff))\r\n                            }\r\n                        }\r\n                    })\r\n                    // console.log(\"mutatingPostResolve client upsert response\", clientResponse)\r\n\r\n                    // console.log(\"diff\", diff.length, fromUint8Array(diff).length, diff)\r\n                    // Y.logUpdate(diff)\r\n                    // console.log(\"encoded state\", fromUint8Array(Y.encodeStateAsUpdate(ydoc1)))\r\n\r\n                    console.log(\"mutatingPostResolve returning data\")\r\n                    // mangle the return into {data: string} so we can handle it on the client\r\n                    return { data: fromUint8Array(diff) } as unknown as any\r\n                }\r\n            }\r\n        }\r\n    },\r\n    graphqlServers: [\r\n        {\r\n            apiNamespace: \"public\",\r\n            serverName: \"public\",\r\n            enableGraphQLEndpoint: true,\r\n            schema: new GraphQLSchema({\r\n                query: new GraphQLObjectType<any, GraphQLExecutionContext>({\r\n                    name: \"Query\",\r\n                    fields: {\r\n                        hello: {\r\n                            type: GraphQLString,\r\n                            resolve: (args: any, ctx: GraphQLExecutionContext) => {\r\n                                return `Hello ${ctx.wundergraph.user?.name || \"World\"}`\r\n                            }\r\n                        }\r\n                    }\r\n                }),\r\n                subscription: new GraphQLObjectType<any, GraphQLExecutionContext>({\r\n                    name: \"Subscription\",\r\n                    fields: {\r\n                        hello: {\r\n                            type: GraphQLString,\r\n                            resolve: (args: any, ctx: GraphQLExecutionContext) => {\r\n                                return `Hello ${ctx.wundergraph.user?.name || \"World\"}`\r\n                            }\r\n                        }\r\n                    }\r\n                })\r\n            })\r\n        }\r\n    ]\r\n}))\r\n", "import * as Y from \"yjs\"\n\ntype managedType = Y.Map<any> | Y.Array<any> | string | number\ntype supportedType = object | string | number\n\nexport function deepEquals(managed: managedType, target: supportedType | supportedType[]): boolean {\n    const managedType = detectManagedType(managed)\n\n    try {\n        var targetType = target.constructor.name\n    } catch (e) {\n        targetType = \"undefined\"\n    }\n\n    if (managedType == \"YArray\" && targetType == \"Array\") {\n        const targetArray = target as Array<any>\n        const managedArray = managed as Y.Array<any>\n\n        const result =\n            managedArray.length == targetArray.length &&\n            targetArray.every((t, i) => deepEquals(managedArray.get(i), targetArray[i]))\n        return result\n    } else if (managedType == \"YMap\" && targetType == \"Object\") {\n        const targetMap = target as Record<string, any>\n        const managedMap = managed as Y.Map<any>\n\n        let targetKeyCount = 0\n        for (let targetKey in targetMap) {\n            targetKeyCount++\n            if (!deepEquals(managedMap.get(targetKey), targetMap[targetKey])) {\n                return false\n            }\n        }\n        return targetKeyCount == Array.from(managedMap.keys()).length\n    } else {\n        return target === managed\n    }\n}\n\nexport function syncronize(managedObj: Y.Map<any> | Y.Array<any>, targetObj: Record<string, any> | any[]): boolean {\n    let changed = false\n\n    const managedType = detectManagedType(managedObj)\n\n    switch (managedType) {\n        case \"YArray\":\n            if (!Array.isArray(targetObj)) {\n                throw new Error(`Sync failed, ${targetObj} was not array`)\n            }\n\n            const managedArray = managedObj as Y.Array<any>\n            const targetArray = targetObj as any[]\n            const outOfRange = Symbol()\n\n            let cursor = 0\n            for (let i = 0; i < targetArray.length; i++) {\n                let match = false\n                const targetValue = targetArray[i]\n                const len = managedArray.length > targetArray.length ? managedArray.length : targetArray.length\n                for (let j = cursor; !match && j < len; j++) {\n                    const managedValue = j < managedArray.length ? managedArray.get(j) : outOfRange\n                    const targetValue = i < targetArray.length ? targetArray[i] : outOfRange\n\n                    if (deepEquals(managedValue, targetValue)) {\n                        for (let x = j - 1; x >= cursor; x--) {\n                            changed = true\n                            managedArray.delete(x)\n                        }\n                        const deletedCount = j - cursor\n                        cursor = j + 1 - deletedCount\n                        match = true\n                    }\n                }\n                if (!match) {\n                    try {\n                        var childType = targetValue.constructor.name\n                    } catch (e) {\n                        childType = \"undefined\"\n                    }\n                    const managedChild = cursor < managedArray.length ? managedArray.get(cursor) : \"undefined\"\n                    const managedType = detectManagedType(managedChild)\n\n                    // but if they're compatible types we should go deeper\n                    // there was no exact match in the list, so assume the immediately next object should be the match\n                    if (\n                        (managedType == \"YMap\" && childType == \"Object\") ||\n                        (managedType == \"YArray\" && childType == \"Array\")\n                    ) {\n                        syncronize(managedChild, targetValue)\n                    } else {\n                        managedArray.insert(cursor, [syncChild(targetValue)])\n                    }\n\n                    cursor++\n                    changed = true\n                }\n            }\n            while (managedArray.length > targetArray.length) {\n                changed = true\n                managedArray.delete(targetArray.length)\n            }\n\n            break\n        case \"YMap\":\n            if (targetObj.constructor.name !== \"Object\") {\n                throw new Error(`Sync failed, ${targetObj} was not object`)\n            }\n\n            const managedMap = managedObj as Y.Map<any>\n            const targetMap = targetObj as Record<string, any>\n\n            for (const key of managedMap.keys()) {\n                if (!(key in targetObj)) {\n                    // item's been removed from target\n                    managedMap.delete(key)\n                    changed = true\n                    continue\n                }\n                const managedChild = managedMap.get(key)\n                const targetChild = targetMap[key]\n\n                const managedType = detectManagedType(managedChild)\n\n                try {\n                    var childType = targetChild.constructor.name\n                } catch (e) {\n                    childType = \"undefined\"\n                }\n\n                if (\n                    (managedType == \"YMap\" && childType !== \"Object\") ||\n                    (managedType == \"YArray\" && childType !== \"Array\") ||\n                    (![\"YMap\", \"YArray\"].includes(managedType) && managedType !== childType)\n                ) {\n                    // this item has fundamentally changed, delete the existing record and recreate it in second pass\n                    managedMap.delete(key)\n                    changed = true\n                } else if (managedType == \"YMap\" || managedType == \"YArray\") {\n                    // they match in types, so go deeper\n                    const childChanged = syncronize(managedChild, targetChild)\n                    changed ||= childChanged\n                } else {\n                    // they are not complex types so just assign it into the map\n                    if (managedChild !== targetChild) {\n                        managedMap.set(key, targetChild)\n                        changed = true\n                    }\n                }\n            }\n\n            for (const key in targetMap) {\n                if (!managedMap.has(key)) {\n                    const child = syncChild(targetMap[key])\n\n                    managedMap.set(key, child)\n                    changed = true\n                }\n            }\n            break\n        default:\n            throw new Error(`can only iterate over Y.Map and Y.Array, got ${managedObj}`)\n    }\n    return changed\n}\n\nfunction syncChild(child: any): any {\n    try {\n        var childType = child.constructor.name\n    } catch (e) {\n        childType = \"undefined\"\n    }\n\n    if (childType == \"Array\") {\n        const arr = new Y.Array()\n\n        syncronize(arr, child)\n        return arr\n    } else if (childType == \"Object\") {\n        const map = new Y.Map()\n\n        syncronize(map, child)\n        return map\n    } else {\n        return child\n    }\n}\n\nfunction detectManagedType(managed: any): string {\n    try {\n        if (managed.length !== undefined && managed.get !== undefined) {\n            return \"YArray\"\n        } else if (managed.keys !== undefined && managed.get !== undefined) {\n            return \"YMap\"\n        } else {\n            return managed.constructor.name\n        }\n    } catch (e) {\n        return \"undefined\"\n    }\n}\n", "\nimport {\n  findIndexSS,\n  getState,\n  splitItem,\n  iterateStructs,\n  UpdateEncoderV2,\n  DSDecoderV1, DSEncoderV1, DSDecoderV2, DSEncoderV2, Item, GC, StructStore, Transaction, ID // eslint-disable-line\n} from '../internals.js'\n\nimport * as array from 'lib0/array'\nimport * as math from 'lib0/math'\nimport * as map from 'lib0/map'\nimport * as encoding from 'lib0/encoding'\nimport * as decoding from 'lib0/decoding'\n\nexport class DeleteItem {\n  /**\n   * @param {number} clock\n   * @param {number} len\n   */\n  constructor (clock, len) {\n    /**\n     * @type {number}\n     */\n    this.clock = clock\n    /**\n     * @type {number}\n     */\n    this.len = len\n  }\n}\n\n/**\n * We no longer maintain a DeleteStore. DeleteSet is a temporary object that is created when needed.\n * - When created in a transaction, it must only be accessed after sorting, and merging\n *   - This DeleteSet is send to other clients\n * - We do not create a DeleteSet when we send a sync message. The DeleteSet message is created directly from StructStore\n * - We read a DeleteSet as part of a sync/update message. In this case the DeleteSet is already sorted and merged.\n */\nexport class DeleteSet {\n  constructor () {\n    /**\n     * @type {Map<number,Array<DeleteItem>>}\n     */\n    this.clients = new Map()\n  }\n}\n\n/**\n * Iterate over all structs that the DeleteSet gc's.\n *\n * @param {Transaction} transaction\n * @param {DeleteSet} ds\n * @param {function(GC|Item):void} f\n *\n * @function\n */\nexport const iterateDeletedStructs = (transaction, ds, f) =>\n  ds.clients.forEach((deletes, clientid) => {\n    const structs = /** @type {Array<GC|Item>} */ (transaction.doc.store.clients.get(clientid))\n    for (let i = 0; i < deletes.length; i++) {\n      const del = deletes[i]\n      iterateStructs(transaction, structs, del.clock, del.len, f)\n    }\n  })\n\n/**\n * @param {Array<DeleteItem>} dis\n * @param {number} clock\n * @return {number|null}\n *\n * @private\n * @function\n */\nexport const findIndexDS = (dis, clock) => {\n  let left = 0\n  let right = dis.length - 1\n  while (left <= right) {\n    const midindex = math.floor((left + right) / 2)\n    const mid = dis[midindex]\n    const midclock = mid.clock\n    if (midclock <= clock) {\n      if (clock < midclock + mid.len) {\n        return midindex\n      }\n      left = midindex + 1\n    } else {\n      right = midindex - 1\n    }\n  }\n  return null\n}\n\n/**\n * @param {DeleteSet} ds\n * @param {ID} id\n * @return {boolean}\n *\n * @private\n * @function\n */\nexport const isDeleted = (ds, id) => {\n  const dis = ds.clients.get(id.client)\n  return dis !== undefined && findIndexDS(dis, id.clock) !== null\n}\n\n/**\n * @param {DeleteSet} ds\n *\n * @private\n * @function\n */\nexport const sortAndMergeDeleteSet = ds => {\n  ds.clients.forEach(dels => {\n    dels.sort((a, b) => a.clock - b.clock)\n    // merge items without filtering or splicing the array\n    // i is the current pointer\n    // j refers to the current insert position for the pointed item\n    // try to merge dels[i] into dels[j-1] or set dels[j]=dels[i]\n    let i, j\n    for (i = 1, j = 1; i < dels.length; i++) {\n      const left = dels[j - 1]\n      const right = dels[i]\n      if (left.clock + left.len >= right.clock) {\n        left.len = math.max(left.len, right.clock + right.len - left.clock)\n      } else {\n        if (j < i) {\n          dels[j] = right\n        }\n        j++\n      }\n    }\n    dels.length = j\n  })\n}\n\n/**\n * @param {Array<DeleteSet>} dss\n * @return {DeleteSet} A fresh DeleteSet\n */\nexport const mergeDeleteSets = dss => {\n  const merged = new DeleteSet()\n  for (let dssI = 0; dssI < dss.length; dssI++) {\n    dss[dssI].clients.forEach((delsLeft, client) => {\n      if (!merged.clients.has(client)) {\n        // Write all missing keys from current ds and all following.\n        // If merged already contains `client` current ds has already been added.\n        /**\n         * @type {Array<DeleteItem>}\n         */\n        const dels = delsLeft.slice()\n        for (let i = dssI + 1; i < dss.length; i++) {\n          array.appendTo(dels, dss[i].clients.get(client) || [])\n        }\n        merged.clients.set(client, dels)\n      }\n    })\n  }\n  sortAndMergeDeleteSet(merged)\n  return merged\n}\n\n/**\n * @param {DeleteSet} ds\n * @param {number} client\n * @param {number} clock\n * @param {number} length\n *\n * @private\n * @function\n */\nexport const addToDeleteSet = (ds, client, clock, length) => {\n  map.setIfUndefined(ds.clients, client, () => []).push(new DeleteItem(clock, length))\n}\n\nexport const createDeleteSet = () => new DeleteSet()\n\n/**\n * @param {StructStore} ss\n * @return {DeleteSet} Merged and sorted DeleteSet\n *\n * @private\n * @function\n */\nexport const createDeleteSetFromStructStore = ss => {\n  const ds = createDeleteSet()\n  ss.clients.forEach((structs, client) => {\n    /**\n     * @type {Array<DeleteItem>}\n     */\n    const dsitems = []\n    for (let i = 0; i < structs.length; i++) {\n      const struct = structs[i]\n      if (struct.deleted) {\n        const clock = struct.id.clock\n        let len = struct.length\n        if (i + 1 < structs.length) {\n          for (let next = structs[i + 1]; i + 1 < structs.length && next.deleted; next = structs[++i + 1]) {\n            len += next.length\n          }\n        }\n        dsitems.push(new DeleteItem(clock, len))\n      }\n    }\n    if (dsitems.length > 0) {\n      ds.clients.set(client, dsitems)\n    }\n  })\n  return ds\n}\n\n/**\n * @param {DSEncoderV1 | DSEncoderV2} encoder\n * @param {DeleteSet} ds\n *\n * @private\n * @function\n */\nexport const writeDeleteSet = (encoder, ds) => {\n  encoding.writeVarUint(encoder.restEncoder, ds.clients.size)\n  ds.clients.forEach((dsitems, client) => {\n    encoder.resetDsCurVal()\n    encoding.writeVarUint(encoder.restEncoder, client)\n    const len = dsitems.length\n    encoding.writeVarUint(encoder.restEncoder, len)\n    for (let i = 0; i < len; i++) {\n      const item = dsitems[i]\n      encoder.writeDsClock(item.clock)\n      encoder.writeDsLen(item.len)\n    }\n  })\n}\n\n/**\n * @param {DSDecoderV1 | DSDecoderV2} decoder\n * @return {DeleteSet}\n *\n * @private\n * @function\n */\nexport const readDeleteSet = decoder => {\n  const ds = new DeleteSet()\n  const numClients = decoding.readVarUint(decoder.restDecoder)\n  for (let i = 0; i < numClients; i++) {\n    decoder.resetDsCurVal()\n    const client = decoding.readVarUint(decoder.restDecoder)\n    const numberOfDeletes = decoding.readVarUint(decoder.restDecoder)\n    if (numberOfDeletes > 0) {\n      const dsField = map.setIfUndefined(ds.clients, client, () => [])\n      for (let i = 0; i < numberOfDeletes; i++) {\n        dsField.push(new DeleteItem(decoder.readDsClock(), decoder.readDsLen()))\n      }\n    }\n  }\n  return ds\n}\n\n/**\n * @todo YDecoder also contains references to String and other Decoders. Would make sense to exchange YDecoder.toUint8Array for YDecoder.DsToUint8Array()..\n */\n\n/**\n * @param {DSDecoderV1 | DSDecoderV2} decoder\n * @param {Transaction} transaction\n * @param {StructStore} store\n * @return {Uint8Array|null} Returns a v2 update containing all deletes that couldn't be applied yet; or null if all deletes were applied successfully.\n *\n * @private\n * @function\n */\nexport const readAndApplyDeleteSet = (decoder, transaction, store) => {\n  const unappliedDS = new DeleteSet()\n  const numClients = decoding.readVarUint(decoder.restDecoder)\n  for (let i = 0; i < numClients; i++) {\n    decoder.resetDsCurVal()\n    const client = decoding.readVarUint(decoder.restDecoder)\n    const numberOfDeletes = decoding.readVarUint(decoder.restDecoder)\n    const structs = store.clients.get(client) || []\n    const state = getState(store, client)\n    for (let i = 0; i < numberOfDeletes; i++) {\n      const clock = decoder.readDsClock()\n      const clockEnd = clock + decoder.readDsLen()\n      if (clock < state) {\n        if (state < clockEnd) {\n          addToDeleteSet(unappliedDS, client, state, clockEnd - state)\n        }\n        let index = findIndexSS(structs, clock)\n        /**\n         * We can ignore the case of GC and Delete structs, because we are going to skip them\n         * @type {Item}\n         */\n        // @ts-ignore\n        let struct = structs[index]\n        // split the first item if necessary\n        if (!struct.deleted && struct.id.clock < clock) {\n          structs.splice(index + 1, 0, splitItem(transaction, struct, clock - struct.id.clock))\n          index++ // increase we now want to use the next struct\n        }\n        while (index < structs.length) {\n          // @ts-ignore\n          struct = structs[index++]\n          if (struct.id.clock < clockEnd) {\n            if (!struct.deleted) {\n              if (clockEnd < struct.id.clock + struct.length) {\n                structs.splice(index, 0, splitItem(transaction, struct, clockEnd - struct.id.clock))\n              }\n              struct.delete(transaction)\n            }\n          } else {\n            break\n          }\n        }\n      } else {\n        addToDeleteSet(unappliedDS, client, clock, clockEnd - clock)\n      }\n    }\n  }\n  if (unappliedDS.clients.size > 0) {\n    const ds = new UpdateEncoderV2()\n    encoding.writeVarUint(ds.restEncoder, 0) // encode 0 structs\n    writeDeleteSet(ds, unappliedDS)\n    return ds.toUint8Array()\n  }\n  return null\n}\n", "\n/**\n * @module encoding\n */\n/*\n * We use the first five bits in the info flag for determining the type of the struct.\n *\n * 0: GC\n * 1: Item with Deleted content\n * 2: Item with JSON content\n * 3: Item with Binary content\n * 4: Item with String content\n * 5: Item with Embed content (for richtext content)\n * 6: Item with Format content (a formatting marker for richtext content)\n * 7: Item with Type\n */\n\nimport {\n  findIndexSS,\n  getState,\n  createID,\n  getStateVector,\n  readAndApplyDeleteSet,\n  writeDeleteSet,\n  createDeleteSetFromStructStore,\n  transact,\n  readItemContent,\n  UpdateDecoderV1,\n  UpdateDecoderV2,\n  UpdateEncoderV1,\n  UpdateEncoderV2,\n  DSEncoderV2,\n  DSDecoderV1,\n  DSEncoderV1,\n  mergeUpdates,\n  mergeUpdatesV2,\n  Skip,\n  diffUpdateV2,\n  convertUpdateFormatV2ToV1,\n  DSDecoderV2, Doc, Transaction, GC, Item, StructStore // eslint-disable-line\n} from '../internals.js'\n\nimport * as encoding from 'lib0/encoding'\nimport * as decoding from 'lib0/decoding'\nimport * as binary from 'lib0/binary'\nimport * as map from 'lib0/map'\nimport * as math from 'lib0/math'\n\n/**\n * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder\n * @param {Array<GC|Item>} structs All structs by `client`\n * @param {number} client\n * @param {number} clock write structs starting with `ID(client,clock)`\n *\n * @function\n */\nconst writeStructs = (encoder, structs, client, clock) => {\n  // write first id\n  clock = math.max(clock, structs[0].id.clock) // make sure the first id exists\n  const startNewStructs = findIndexSS(structs, clock)\n  // write # encoded structs\n  encoding.writeVarUint(encoder.restEncoder, structs.length - startNewStructs)\n  encoder.writeClient(client)\n  encoding.writeVarUint(encoder.restEncoder, clock)\n  const firstStruct = structs[startNewStructs]\n  // write first struct with an offset\n  firstStruct.write(encoder, clock - firstStruct.id.clock)\n  for (let i = startNewStructs + 1; i < structs.length; i++) {\n    structs[i].write(encoder, 0)\n  }\n}\n\n/**\n * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder\n * @param {StructStore} store\n * @param {Map<number,number>} _sm\n *\n * @private\n * @function\n */\nexport const writeClientsStructs = (encoder, store, _sm) => {\n  // we filter all valid _sm entries into sm\n  const sm = new Map()\n  _sm.forEach((clock, client) => {\n    // only write if new structs are available\n    if (getState(store, client) > clock) {\n      sm.set(client, clock)\n    }\n  })\n  getStateVector(store).forEach((clock, client) => {\n    if (!_sm.has(client)) {\n      sm.set(client, 0)\n    }\n  })\n  // write # states that were updated\n  encoding.writeVarUint(encoder.restEncoder, sm.size)\n  // Write items with higher client ids first\n  // This heavily improves the conflict algorithm.\n  Array.from(sm.entries()).sort((a, b) => b[0] - a[0]).forEach(([client, clock]) => {\n    // @ts-ignore\n    writeStructs(encoder, store.clients.get(client), client, clock)\n  })\n}\n\n/**\n * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder The decoder object to read data from.\n * @param {Doc} doc\n * @return {Map<number, { i: number, refs: Array<Item | GC> }>}\n *\n * @private\n * @function\n */\nexport const readClientsStructRefs = (decoder, doc) => {\n  /**\n   * @type {Map<number, { i: number, refs: Array<Item | GC> }>}\n   */\n  const clientRefs = map.create()\n  const numOfStateUpdates = decoding.readVarUint(decoder.restDecoder)\n  for (let i = 0; i < numOfStateUpdates; i++) {\n    const numberOfStructs = decoding.readVarUint(decoder.restDecoder)\n    /**\n     * @type {Array<GC|Item>}\n     */\n    const refs = new Array(numberOfStructs)\n    const client = decoder.readClient()\n    let clock = decoding.readVarUint(decoder.restDecoder)\n    // const start = performance.now()\n    clientRefs.set(client, { i: 0, refs })\n    for (let i = 0; i < numberOfStructs; i++) {\n      const info = decoder.readInfo()\n      switch (binary.BITS5 & info) {\n        case 0: { // GC\n          const len = decoder.readLen()\n          refs[i] = new GC(createID(client, clock), len)\n          clock += len\n          break\n        }\n        case 10: { // Skip Struct (nothing to apply)\n          // @todo we could reduce the amount of checks by adding Skip struct to clientRefs so we know that something is missing.\n          const len = decoding.readVarUint(decoder.restDecoder)\n          refs[i] = new Skip(createID(client, clock), len)\n          clock += len\n          break\n        }\n        default: { // Item with content\n          /**\n           * The optimized implementation doesn't use any variables because inlining variables is faster.\n           * Below a non-optimized version is shown that implements the basic algorithm with\n           * a few comments\n           */\n          const cantCopyParentInfo = (info & (binary.BIT7 | binary.BIT8)) === 0\n          // If parent = null and neither left nor right are defined, then we know that `parent` is child of `y`\n          // and we read the next string as parentYKey.\n          // It indicates how we store/retrieve parent from `y.share`\n          // @type {string|null}\n          const struct = new Item(\n            createID(client, clock),\n            null, // leftd\n            (info & binary.BIT8) === binary.BIT8 ? decoder.readLeftID() : null, // origin\n            null, // right\n            (info & binary.BIT7) === binary.BIT7 ? decoder.readRightID() : null, // right origin\n            cantCopyParentInfo ? (decoder.readParentInfo() ? doc.get(decoder.readString()) : decoder.readLeftID()) : null, // parent\n            cantCopyParentInfo && (info & binary.BIT6) === binary.BIT6 ? decoder.readString() : null, // parentSub\n            readItemContent(decoder, info) // item content\n          )\n          /* A non-optimized implementation of the above algorithm:\n\n          // The item that was originally to the left of this item.\n          const origin = (info & binary.BIT8) === binary.BIT8 ? decoder.readLeftID() : null\n          // The item that was originally to the right of this item.\n          const rightOrigin = (info & binary.BIT7) === binary.BIT7 ? decoder.readRightID() : null\n          const cantCopyParentInfo = (info & (binary.BIT7 | binary.BIT8)) === 0\n          const hasParentYKey = cantCopyParentInfo ? decoder.readParentInfo() : false\n          // If parent = null and neither left nor right are defined, then we know that `parent` is child of `y`\n          // and we read the next string as parentYKey.\n          // It indicates how we store/retrieve parent from `y.share`\n          // @type {string|null}\n          const parentYKey = cantCopyParentInfo && hasParentYKey ? decoder.readString() : null\n\n          const struct = new Item(\n            createID(client, clock),\n            null, // leftd\n            origin, // origin\n            null, // right\n            rightOrigin, // right origin\n            cantCopyParentInfo && !hasParentYKey ? decoder.readLeftID() : (parentYKey !== null ? doc.get(parentYKey) : null), // parent\n            cantCopyParentInfo && (info & binary.BIT6) === binary.BIT6 ? decoder.readString() : null, // parentSub\n            readItemContent(decoder, info) // item content\n          )\n          */\n          refs[i] = struct\n          clock += struct.length\n        }\n      }\n    }\n    // console.log('time to read: ', performance.now() - start) // @todo remove\n  }\n  return clientRefs\n}\n\n/**\n * Resume computing structs generated by struct readers.\n *\n * While there is something to do, we integrate structs in this order\n * 1. top element on stack, if stack is not empty\n * 2. next element from current struct reader (if empty, use next struct reader)\n *\n * If struct causally depends on another struct (ref.missing), we put next reader of\n * `ref.id.client` on top of stack.\n *\n * At some point we find a struct that has no causal dependencies,\n * then we start emptying the stack.\n *\n * It is not possible to have circles: i.e. struct1 (from client1) depends on struct2 (from client2)\n * depends on struct3 (from client1). Therefore the max stack size is eqaul to `structReaders.length`.\n *\n * This method is implemented in a way so that we can resume computation if this update\n * causally depends on another update.\n *\n * @param {Transaction} transaction\n * @param {StructStore} store\n * @param {Map<number, { i: number, refs: (GC | Item)[] }>} clientsStructRefs\n * @return { null | { update: Uint8Array, missing: Map<number,number> } }\n *\n * @private\n * @function\n */\nconst integrateStructs = (transaction, store, clientsStructRefs) => {\n  /**\n   * @type {Array<Item | GC>}\n   */\n  const stack = []\n  // sort them so that we take the higher id first, in case of conflicts the lower id will probably not conflict with the id from the higher user.\n  let clientsStructRefsIds = Array.from(clientsStructRefs.keys()).sort((a, b) => a - b)\n  if (clientsStructRefsIds.length === 0) {\n    return null\n  }\n  const getNextStructTarget = () => {\n    if (clientsStructRefsIds.length === 0) {\n      return null\n    }\n    let nextStructsTarget = /** @type {{i:number,refs:Array<GC|Item>}} */ (clientsStructRefs.get(clientsStructRefsIds[clientsStructRefsIds.length - 1]))\n    while (nextStructsTarget.refs.length === nextStructsTarget.i) {\n      clientsStructRefsIds.pop()\n      if (clientsStructRefsIds.length > 0) {\n        nextStructsTarget = /** @type {{i:number,refs:Array<GC|Item>}} */ (clientsStructRefs.get(clientsStructRefsIds[clientsStructRefsIds.length - 1]))\n      } else {\n        return null\n      }\n    }\n    return nextStructsTarget\n  }\n  let curStructsTarget = getNextStructTarget()\n  if (curStructsTarget === null && stack.length === 0) {\n    return null\n  }\n\n  /**\n   * @type {StructStore}\n   */\n  const restStructs = new StructStore()\n  const missingSV = new Map()\n  /**\n   * @param {number} client\n   * @param {number} clock\n   */\n  const updateMissingSv = (client, clock) => {\n    const mclock = missingSV.get(client)\n    if (mclock == null || mclock > clock) {\n      missingSV.set(client, clock)\n    }\n  }\n  /**\n   * @type {GC|Item}\n   */\n  let stackHead = /** @type {any} */ (curStructsTarget).refs[/** @type {any} */ (curStructsTarget).i++]\n  // caching the state because it is used very often\n  const state = new Map()\n\n  const addStackToRestSS = () => {\n    for (const item of stack) {\n      const client = item.id.client\n      const unapplicableItems = clientsStructRefs.get(client)\n      if (unapplicableItems) {\n        // decrement because we weren't able to apply previous operation\n        unapplicableItems.i--\n        restStructs.clients.set(client, unapplicableItems.refs.slice(unapplicableItems.i))\n        clientsStructRefs.delete(client)\n        unapplicableItems.i = 0\n        unapplicableItems.refs = []\n      } else {\n        // item was the last item on clientsStructRefs and the field was already cleared. Add item to restStructs and continue\n        restStructs.clients.set(client, [item])\n      }\n      // remove client from clientsStructRefsIds to prevent users from applying the same update again\n      clientsStructRefsIds = clientsStructRefsIds.filter(c => c !== client)\n    }\n    stack.length = 0\n  }\n\n  // iterate over all struct readers until we are done\n  while (true) {\n    if (stackHead.constructor !== Skip) {\n      const localClock = map.setIfUndefined(state, stackHead.id.client, () => getState(store, stackHead.id.client))\n      const offset = localClock - stackHead.id.clock\n      if (offset < 0) {\n        // update from the same client is missing\n        stack.push(stackHead)\n        updateMissingSv(stackHead.id.client, stackHead.id.clock - 1)\n        // hid a dead wall, add all items from stack to restSS\n        addStackToRestSS()\n      } else {\n        const missing = stackHead.getMissing(transaction, store)\n        if (missing !== null) {\n          stack.push(stackHead)\n          // get the struct reader that has the missing struct\n          /**\n           * @type {{ refs: Array<GC|Item>, i: number }}\n           */\n          const structRefs = clientsStructRefs.get(/** @type {number} */ (missing)) || { refs: [], i: 0 }\n          if (structRefs.refs.length === structRefs.i) {\n            // This update message causally depends on another update message that doesn't exist yet\n            updateMissingSv(/** @type {number} */ (missing), getState(store, missing))\n            addStackToRestSS()\n          } else {\n            stackHead = structRefs.refs[structRefs.i++]\n            continue\n          }\n        } else if (offset === 0 || offset < stackHead.length) {\n          // all fine, apply the stackhead\n          stackHead.integrate(transaction, offset)\n          state.set(stackHead.id.client, stackHead.id.clock + stackHead.length)\n        }\n      }\n    }\n    // iterate to next stackHead\n    if (stack.length > 0) {\n      stackHead = /** @type {GC|Item} */ (stack.pop())\n    } else if (curStructsTarget !== null && curStructsTarget.i < curStructsTarget.refs.length) {\n      stackHead = /** @type {GC|Item} */ (curStructsTarget.refs[curStructsTarget.i++])\n    } else {\n      curStructsTarget = getNextStructTarget()\n      if (curStructsTarget === null) {\n        // we are done!\n        break\n      } else {\n        stackHead = /** @type {GC|Item} */ (curStructsTarget.refs[curStructsTarget.i++])\n      }\n    }\n  }\n  if (restStructs.clients.size > 0) {\n    const encoder = new UpdateEncoderV2()\n    writeClientsStructs(encoder, restStructs, new Map())\n    // write empty deleteset\n    // writeDeleteSet(encoder, new DeleteSet())\n    encoding.writeVarUint(encoder.restEncoder, 0) // => no need for an extra function call, just write 0 deletes\n    return { missing: missingSV, update: encoder.toUint8Array() }\n  }\n  return null\n}\n\n/**\n * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder\n * @param {Transaction} transaction\n *\n * @private\n * @function\n */\nexport const writeStructsFromTransaction = (encoder, transaction) => writeClientsStructs(encoder, transaction.doc.store, transaction.beforeState)\n\n/**\n * Read and apply a document update.\n *\n * This function has the same effect as `applyUpdate` but accepts an decoder.\n *\n * @param {decoding.Decoder} decoder\n * @param {Doc} ydoc\n * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`\n * @param {UpdateDecoderV1 | UpdateDecoderV2} [structDecoder]\n *\n * @function\n */\nexport const readUpdateV2 = (decoder, ydoc, transactionOrigin, structDecoder = new UpdateDecoderV2(decoder)) =>\n  transact(ydoc, transaction => {\n    // force that transaction.local is set to non-local\n    transaction.local = false\n    let retry = false\n    const doc = transaction.doc\n    const store = doc.store\n    // let start = performance.now()\n    const ss = readClientsStructRefs(structDecoder, doc)\n    // console.log('time to read structs: ', performance.now() - start) // @todo remove\n    // start = performance.now()\n    // console.log('time to merge: ', performance.now() - start) // @todo remove\n    // start = performance.now()\n    const restStructs = integrateStructs(transaction, store, ss)\n    const pending = store.pendingStructs\n    if (pending) {\n      // check if we can apply something\n      for (const [client, clock] of pending.missing) {\n        if (clock < getState(store, client)) {\n          retry = true\n          break\n        }\n      }\n      if (restStructs) {\n        // merge restStructs into store.pending\n        for (const [client, clock] of restStructs.missing) {\n          const mclock = pending.missing.get(client)\n          if (mclock == null || mclock > clock) {\n            pending.missing.set(client, clock)\n          }\n        }\n        pending.update = mergeUpdatesV2([pending.update, restStructs.update])\n      }\n    } else {\n      store.pendingStructs = restStructs\n    }\n    // console.log('time to integrate: ', performance.now() - start) // @todo remove\n    // start = performance.now()\n    const dsRest = readAndApplyDeleteSet(structDecoder, transaction, store)\n    if (store.pendingDs) {\n      // @todo we could make a lower-bound state-vector check as we do above\n      const pendingDSUpdate = new UpdateDecoderV2(decoding.createDecoder(store.pendingDs))\n      decoding.readVarUint(pendingDSUpdate.restDecoder) // read 0 structs, because we only encode deletes in pendingdsupdate\n      const dsRest2 = readAndApplyDeleteSet(pendingDSUpdate, transaction, store)\n      if (dsRest && dsRest2) {\n        // case 1: ds1 != null && ds2 != null\n        store.pendingDs = mergeUpdatesV2([dsRest, dsRest2])\n      } else {\n        // case 2: ds1 != null\n        // case 3: ds2 != null\n        // case 4: ds1 == null && ds2 == null\n        store.pendingDs = dsRest || dsRest2\n      }\n    } else {\n      // Either dsRest == null && pendingDs == null OR dsRest != null\n      store.pendingDs = dsRest\n    }\n    // console.log('time to cleanup: ', performance.now() - start) // @todo remove\n    // start = performance.now()\n\n    // console.log('time to resume delete readers: ', performance.now() - start) // @todo remove\n    // start = performance.now()\n    if (retry) {\n      const update = /** @type {{update: Uint8Array}} */ (store.pendingStructs).update\n      store.pendingStructs = null\n      applyUpdateV2(transaction.doc, update)\n    }\n  }, transactionOrigin, false)\n\n/**\n * Read and apply a document update.\n *\n * This function has the same effect as `applyUpdate` but accepts an decoder.\n *\n * @param {decoding.Decoder} decoder\n * @param {Doc} ydoc\n * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`\n *\n * @function\n */\nexport const readUpdate = (decoder, ydoc, transactionOrigin) => readUpdateV2(decoder, ydoc, transactionOrigin, new UpdateDecoderV1(decoder))\n\n/**\n * Apply a document update created by, for example, `y.on('update', update => ..)` or `update = encodeStateAsUpdate()`.\n *\n * This function has the same effect as `readUpdate` but accepts an Uint8Array instead of a Decoder.\n *\n * @param {Doc} ydoc\n * @param {Uint8Array} update\n * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`\n * @param {typeof UpdateDecoderV1 | typeof UpdateDecoderV2} [YDecoder]\n *\n * @function\n */\nexport const applyUpdateV2 = (ydoc, update, transactionOrigin, YDecoder = UpdateDecoderV2) => {\n  const decoder = decoding.createDecoder(update)\n  readUpdateV2(decoder, ydoc, transactionOrigin, new YDecoder(decoder))\n}\n\n/**\n * Apply a document update created by, for example, `y.on('update', update => ..)` or `update = encodeStateAsUpdate()`.\n *\n * This function has the same effect as `readUpdate` but accepts an Uint8Array instead of a Decoder.\n *\n * @param {Doc} ydoc\n * @param {Uint8Array} update\n * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`\n *\n * @function\n */\nexport const applyUpdate = (ydoc, update, transactionOrigin) => applyUpdateV2(ydoc, update, transactionOrigin, UpdateDecoderV1)\n\n/**\n * Write all the document as a single update message. If you specify the state of the remote client (`targetStateVector`) it will\n * only write the operations that are missing.\n *\n * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder\n * @param {Doc} doc\n * @param {Map<number,number>} [targetStateVector] The state of the target that receives the update. Leave empty to write all known structs\n *\n * @function\n */\nexport const writeStateAsUpdate = (encoder, doc, targetStateVector = new Map()) => {\n  writeClientsStructs(encoder, doc.store, targetStateVector)\n  writeDeleteSet(encoder, createDeleteSetFromStructStore(doc.store))\n}\n\n/**\n * Write all the document as a single update message that can be applied on the remote document. If you specify the state of the remote client (`targetState`) it will\n * only write the operations that are missing.\n *\n * Use `writeStateAsUpdate` instead if you are working with lib0/encoding.js#Encoder\n *\n * @param {Doc} doc\n * @param {Uint8Array} [encodedTargetStateVector] The state of the target that receives the update. Leave empty to write all known structs\n * @param {UpdateEncoderV1 | UpdateEncoderV2} [encoder]\n * @return {Uint8Array}\n *\n * @function\n */\nexport const encodeStateAsUpdateV2 = (doc, encodedTargetStateVector = new Uint8Array([0]), encoder = new UpdateEncoderV2()) => {\n  const targetStateVector = decodeStateVector(encodedTargetStateVector)\n  writeStateAsUpdate(encoder, doc, targetStateVector)\n  const updates = [encoder.toUint8Array()]\n  // also add the pending updates (if there are any)\n  if (doc.store.pendingDs) {\n    updates.push(doc.store.pendingDs)\n  }\n  if (doc.store.pendingStructs) {\n    updates.push(diffUpdateV2(doc.store.pendingStructs.update, encodedTargetStateVector))\n  }\n  if (updates.length > 1) {\n    if (encoder.constructor === UpdateEncoderV1) {\n      return mergeUpdates(updates.map((update, i) => i === 0 ? update : convertUpdateFormatV2ToV1(update)))\n    } else if (encoder.constructor === UpdateEncoderV2) {\n      return mergeUpdatesV2(updates)\n    }\n  }\n  return updates[0]\n}\n\n/**\n * Write all the document as a single update message that can be applied on the remote document. If you specify the state of the remote client (`targetState`) it will\n * only write the operations that are missing.\n *\n * Use `writeStateAsUpdate` instead if you are working with lib0/encoding.js#Encoder\n *\n * @param {Doc} doc\n * @param {Uint8Array} [encodedTargetStateVector] The state of the target that receives the update. Leave empty to write all known structs\n * @return {Uint8Array}\n *\n * @function\n */\nexport const encodeStateAsUpdate = (doc, encodedTargetStateVector) => encodeStateAsUpdateV2(doc, encodedTargetStateVector, new UpdateEncoderV1())\n\n/**\n * Read state vector from Decoder and return as Map\n *\n * @param {DSDecoderV1 | DSDecoderV2} decoder\n * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.\n *\n * @function\n */\nexport const readStateVector = decoder => {\n  const ss = new Map()\n  const ssLength = decoding.readVarUint(decoder.restDecoder)\n  for (let i = 0; i < ssLength; i++) {\n    const client = decoding.readVarUint(decoder.restDecoder)\n    const clock = decoding.readVarUint(decoder.restDecoder)\n    ss.set(client, clock)\n  }\n  return ss\n}\n\n/**\n * Read decodedState and return State as Map.\n *\n * @param {Uint8Array} decodedState\n * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.\n *\n * @function\n */\n// export const decodeStateVectorV2 = decodedState => readStateVector(new DSDecoderV2(decoding.createDecoder(decodedState)))\n\n/**\n * Read decodedState and return State as Map.\n *\n * @param {Uint8Array} decodedState\n * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.\n *\n * @function\n */\nexport const decodeStateVector = decodedState => readStateVector(new DSDecoderV1(decoding.createDecoder(decodedState)))\n\n/**\n * @param {DSEncoderV1 | DSEncoderV2} encoder\n * @param {Map<number,number>} sv\n * @function\n */\nexport const writeStateVector = (encoder, sv) => {\n  encoding.writeVarUint(encoder.restEncoder, sv.size)\n  Array.from(sv.entries()).sort((a, b) => b[0] - a[0]).forEach(([client, clock]) => {\n    encoding.writeVarUint(encoder.restEncoder, client) // @todo use a special client decoder that is based on mapping\n    encoding.writeVarUint(encoder.restEncoder, clock)\n  })\n  return encoder\n}\n\n/**\n * @param {DSEncoderV1 | DSEncoderV2} encoder\n * @param {Doc} doc\n *\n * @function\n */\nexport const writeDocumentStateVector = (encoder, doc) => writeStateVector(encoder, getStateVector(doc.store))\n\n/**\n * Encode State as Uint8Array.\n *\n * @param {Doc|Map<number,number>} doc\n * @param {DSEncoderV1 | DSEncoderV2} [encoder]\n * @return {Uint8Array}\n *\n * @function\n */\nexport const encodeStateVectorV2 = (doc, encoder = new DSEncoderV2()) => {\n  if (doc instanceof Map) {\n    writeStateVector(encoder, doc)\n  } else {\n    writeDocumentStateVector(encoder, doc)\n  }\n  return encoder.toUint8Array()\n}\n\n/**\n * Encode State as Uint8Array.\n *\n * @param {Doc|Map<number,number>} doc\n * @return {Uint8Array}\n *\n * @function\n */\nexport const encodeStateVector = doc => encodeStateVectorV2(doc, new DSEncoderV1())\n", "\nimport {\n  GC,\n  splitItem,\n  Transaction, ID, Item, DSDecoderV2 // eslint-disable-line\n} from '../internals.js'\n\nimport * as math from 'lib0/math'\nimport * as error from 'lib0/error'\n\nexport class StructStore {\n  constructor () {\n    /**\n     * @type {Map<number,Array<GC|Item>>}\n     */\n    this.clients = new Map()\n    /**\n     * @type {null | { missing: Map<number, number>, update: Uint8Array }}\n     */\n    this.pendingStructs = null\n    /**\n     * @type {null | Uint8Array}\n     */\n    this.pendingDs = null\n  }\n}\n\n/**\n * Return the states as a Map<client,clock>.\n * Note that clock refers to the next expected clock id.\n *\n * @param {StructStore} store\n * @return {Map<number,number>}\n *\n * @public\n * @function\n */\nexport const getStateVector = store => {\n  const sm = new Map()\n  store.clients.forEach((structs, client) => {\n    const struct = structs[structs.length - 1]\n    sm.set(client, struct.id.clock + struct.length)\n  })\n  return sm\n}\n\n/**\n * @param {StructStore} store\n * @param {number} client\n * @return {number}\n *\n * @public\n * @function\n */\nexport const getState = (store, client) => {\n  const structs = store.clients.get(client)\n  if (structs === undefined) {\n    return 0\n  }\n  const lastStruct = structs[structs.length - 1]\n  return lastStruct.id.clock + lastStruct.length\n}\n\n/**\n * @param {StructStore} store\n *\n * @private\n * @function\n */\nexport const integretyCheck = store => {\n  store.clients.forEach(structs => {\n    for (let i = 1; i < structs.length; i++) {\n      const l = structs[i - 1]\n      const r = structs[i]\n      if (l.id.clock + l.length !== r.id.clock) {\n        throw new Error('StructStore failed integrety check')\n      }\n    }\n  })\n}\n\n/**\n * @param {StructStore} store\n * @param {GC|Item} struct\n *\n * @private\n * @function\n */\nexport const addStruct = (store, struct) => {\n  let structs = store.clients.get(struct.id.client)\n  if (structs === undefined) {\n    structs = []\n    store.clients.set(struct.id.client, structs)\n  } else {\n    const lastStruct = structs[structs.length - 1]\n    if (lastStruct.id.clock + lastStruct.length !== struct.id.clock) {\n      throw error.unexpectedCase()\n    }\n  }\n  structs.push(struct)\n}\n\n/**\n * Perform a binary search on a sorted array\n * @param {Array<Item|GC>} structs\n * @param {number} clock\n * @return {number}\n *\n * @private\n * @function\n */\nexport const findIndexSS = (structs, clock) => {\n  let left = 0\n  let right = structs.length - 1\n  let mid = structs[right]\n  let midclock = mid.id.clock\n  if (midclock === clock) {\n    return right\n  }\n  // @todo does it even make sense to pivot the search?\n  // If a good split misses, it might actually increase the time to find the correct item.\n  // Currently, the only advantage is that search with pivoting might find the item on the first try.\n  let midindex = math.floor((clock / (midclock + mid.length - 1)) * right) // pivoting the search\n  while (left <= right) {\n    mid = structs[midindex]\n    midclock = mid.id.clock\n    if (midclock <= clock) {\n      if (clock < midclock + mid.length) {\n        return midindex\n      }\n      left = midindex + 1\n    } else {\n      right = midindex - 1\n    }\n    midindex = math.floor((left + right) / 2)\n  }\n  // Always check state before looking for a struct in StructStore\n  // Therefore the case of not finding a struct is unexpected\n  throw error.unexpectedCase()\n}\n\n/**\n * Expects that id is actually in store. This function throws or is an infinite loop otherwise.\n *\n * @param {StructStore} store\n * @param {ID} id\n * @return {GC|Item}\n *\n * @private\n * @function\n */\nexport const find = (store, id) => {\n  /**\n   * @type {Array<GC|Item>}\n   */\n  // @ts-ignore\n  const structs = store.clients.get(id.client)\n  return structs[findIndexSS(structs, id.clock)]\n}\n\n/**\n * Expects that id is actually in store. This function throws or is an infinite loop otherwise.\n * @private\n * @function\n */\nexport const getItem = /** @type {function(StructStore,ID):Item} */ (find)\n\n/**\n * @param {Transaction} transaction\n * @param {Array<Item|GC>} structs\n * @param {number} clock\n */\nexport const findIndexCleanStart = (transaction, structs, clock) => {\n  const index = findIndexSS(structs, clock)\n  const struct = structs[index]\n  if (struct.id.clock < clock && struct instanceof Item) {\n    structs.splice(index + 1, 0, splitItem(transaction, struct, clock - struct.id.clock))\n    return index + 1\n  }\n  return index\n}\n\n/**\n * Expects that id is actually in store. This function throws or is an infinite loop otherwise.\n *\n * @param {Transaction} transaction\n * @param {ID} id\n * @return {Item}\n *\n * @private\n * @function\n */\nexport const getItemCleanStart = (transaction, id) => {\n  const structs = /** @type {Array<Item>} */ (transaction.doc.store.clients.get(id.client))\n  return structs[findIndexCleanStart(transaction, structs, id.clock)]\n}\n\n/**\n * Expects that id is actually in store. This function throws or is an infinite loop otherwise.\n *\n * @param {Transaction} transaction\n * @param {StructStore} store\n * @param {ID} id\n * @return {Item}\n *\n * @private\n * @function\n */\nexport const getItemCleanEnd = (transaction, store, id) => {\n  /**\n   * @type {Array<Item>}\n   */\n  // @ts-ignore\n  const structs = store.clients.get(id.client)\n  const index = findIndexSS(structs, id.clock)\n  const struct = structs[index]\n  if (id.clock !== struct.id.clock + struct.length - 1 && struct.constructor !== GC) {\n    structs.splice(index + 1, 0, splitItem(transaction, struct, id.clock - struct.id.clock + 1))\n  }\n  return struct\n}\n\n/**\n * Replace `item` with `newitem` in store\n * @param {StructStore} store\n * @param {GC|Item} struct\n * @param {GC|Item} newStruct\n *\n * @private\n * @function\n */\nexport const replaceStruct = (store, struct, newStruct) => {\n  const structs = /** @type {Array<GC|Item>} */ (store.clients.get(struct.id.client))\n  structs[findIndexSS(structs, struct.id.clock)] = newStruct\n}\n\n/**\n * Iterate over a range of structs\n *\n * @param {Transaction} transaction\n * @param {Array<Item|GC>} structs\n * @param {number} clockStart Inclusive start\n * @param {number} len\n * @param {function(GC|Item):void} f\n *\n * @function\n */\nexport const iterateStructs = (transaction, structs, clockStart, len, f) => {\n  if (len === 0) {\n    return\n  }\n  const clockEnd = clockStart + len\n  let index = findIndexCleanStart(transaction, structs, clockStart)\n  let struct\n  do {\n    struct = structs[index++]\n    if (clockEnd < struct.id.clock + struct.length) {\n      findIndexCleanStart(transaction, structs, clockEnd)\n    }\n    f(struct)\n  } while (index < structs.length && structs[index].id.clock < clockEnd)\n}\n", "\nimport {\n  getState,\n  writeStructsFromTransaction,\n  writeDeleteSet,\n  DeleteSet,\n  sortAndMergeDeleteSet,\n  getStateVector,\n  findIndexSS,\n  callEventHandlerListeners,\n  Item,\n  generateNewClientId,\n  createID,\n  UpdateEncoderV1, UpdateEncoderV2, GC, StructStore, AbstractType, AbstractStruct, YEvent, Doc // eslint-disable-line\n} from '../internals.js'\n\nimport * as map from 'lib0/map'\nimport * as math from 'lib0/math'\nimport * as set from 'lib0/set'\nimport * as logging from 'lib0/logging'\nimport { callAll } from 'lib0/function'\n\n/**\n * A transaction is created for every change on the Yjs model. It is possible\n * to bundle changes on the Yjs model in a single transaction to\n * minimize the number on messages sent and the number of observer calls.\n * If possible the user of this library should bundle as many changes as\n * possible. Here is an example to illustrate the advantages of bundling:\n *\n * @example\n * const map = y.define('map', YMap)\n * // Log content when change is triggered\n * map.observe(() => {\n *   console.log('change triggered')\n * })\n * // Each change on the map type triggers a log message:\n * map.set('a', 0) // => \"change triggered\"\n * map.set('b', 0) // => \"change triggered\"\n * // When put in a transaction, it will trigger the log after the transaction:\n * y.transact(() => {\n *   map.set('a', 1)\n *   map.set('b', 1)\n * }) // => \"change triggered\"\n *\n * @public\n */\nexport class Transaction {\n  /**\n   * @param {Doc} doc\n   * @param {any} origin\n   * @param {boolean} local\n   */\n  constructor (doc, origin, local) {\n    /**\n     * The Yjs instance.\n     * @type {Doc}\n     */\n    this.doc = doc\n    /**\n     * Describes the set of deleted items by ids\n     * @type {DeleteSet}\n     */\n    this.deleteSet = new DeleteSet()\n    /**\n     * Holds the state before the transaction started.\n     * @type {Map<Number,Number>}\n     */\n    this.beforeState = getStateVector(doc.store)\n    /**\n     * Holds the state after the transaction.\n     * @type {Map<Number,Number>}\n     */\n    this.afterState = new Map()\n    /**\n     * All types that were directly modified (property added or child\n     * inserted/deleted). New types are not included in this Set.\n     * Maps from type to parentSubs (`item.parentSub = null` for YArray)\n     * @type {Map<AbstractType<YEvent<any>>,Set<String|null>>}\n     */\n    this.changed = new Map()\n    /**\n     * Stores the events for the types that observe also child elements.\n     * It is mainly used by `observeDeep`.\n     * @type {Map<AbstractType<YEvent<any>>,Array<YEvent<any>>>}\n     */\n    this.changedParentTypes = new Map()\n    /**\n     * @type {Array<AbstractStruct>}\n     */\n    this._mergeStructs = []\n    /**\n     * @type {any}\n     */\n    this.origin = origin\n    /**\n     * Stores meta information on the transaction\n     * @type {Map<any,any>}\n     */\n    this.meta = new Map()\n    /**\n     * Whether this change originates from this doc.\n     * @type {boolean}\n     */\n    this.local = local\n    /**\n     * @type {Set<Doc>}\n     */\n    this.subdocsAdded = new Set()\n    /**\n     * @type {Set<Doc>}\n     */\n    this.subdocsRemoved = new Set()\n    /**\n     * @type {Set<Doc>}\n     */\n    this.subdocsLoaded = new Set()\n  }\n}\n\n/**\n * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder\n * @param {Transaction} transaction\n * @return {boolean} Whether data was written.\n */\nexport const writeUpdateMessageFromTransaction = (encoder, transaction) => {\n  if (transaction.deleteSet.clients.size === 0 && !map.any(transaction.afterState, (clock, client) => transaction.beforeState.get(client) !== clock)) {\n    return false\n  }\n  sortAndMergeDeleteSet(transaction.deleteSet)\n  writeStructsFromTransaction(encoder, transaction)\n  writeDeleteSet(encoder, transaction.deleteSet)\n  return true\n}\n\n/**\n * @param {Transaction} transaction\n *\n * @private\n * @function\n */\nexport const nextID = transaction => {\n  const y = transaction.doc\n  return createID(y.clientID, getState(y.store, y.clientID))\n}\n\n/**\n * If `type.parent` was added in current transaction, `type` technically\n * did not change, it was just added and we should not fire events for `type`.\n *\n * @param {Transaction} transaction\n * @param {AbstractType<YEvent<any>>} type\n * @param {string|null} parentSub\n */\nexport const addChangedTypeToTransaction = (transaction, type, parentSub) => {\n  const item = type._item\n  if (item === null || (item.id.clock < (transaction.beforeState.get(item.id.client) || 0) && !item.deleted)) {\n    map.setIfUndefined(transaction.changed, type, set.create).add(parentSub)\n  }\n}\n\n/**\n * @param {Array<AbstractStruct>} structs\n * @param {number} pos\n */\nconst tryToMergeWithLeft = (structs, pos) => {\n  const left = structs[pos - 1]\n  const right = structs[pos]\n  if (left.deleted === right.deleted && left.constructor === right.constructor) {\n    if (left.mergeWith(right)) {\n      structs.splice(pos, 1)\n      if (right instanceof Item && right.parentSub !== null && /** @type {AbstractType<any>} */ (right.parent)._map.get(right.parentSub) === right) {\n        /** @type {AbstractType<any>} */ (right.parent)._map.set(right.parentSub, /** @type {Item} */ (left))\n      }\n    }\n  }\n}\n\n/**\n * @param {DeleteSet} ds\n * @param {StructStore} store\n * @param {function(Item):boolean} gcFilter\n */\nconst tryGcDeleteSet = (ds, store, gcFilter) => {\n  for (const [client, deleteItems] of ds.clients.entries()) {\n    const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client))\n    for (let di = deleteItems.length - 1; di >= 0; di--) {\n      const deleteItem = deleteItems[di]\n      const endDeleteItemClock = deleteItem.clock + deleteItem.len\n      for (\n        let si = findIndexSS(structs, deleteItem.clock), struct = structs[si];\n        si < structs.length && struct.id.clock < endDeleteItemClock;\n        struct = structs[++si]\n      ) {\n        const struct = structs[si]\n        if (deleteItem.clock + deleteItem.len <= struct.id.clock) {\n          break\n        }\n        if (struct instanceof Item && struct.deleted && !struct.keep && gcFilter(struct)) {\n          struct.gc(store, false)\n        }\n      }\n    }\n  }\n}\n\n/**\n * @param {DeleteSet} ds\n * @param {StructStore} store\n */\nconst tryMergeDeleteSet = (ds, store) => {\n  // try to merge deleted / gc'd items\n  // merge from right to left for better efficiecy and so we don't miss any merge targets\n  ds.clients.forEach((deleteItems, client) => {\n    const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client))\n    for (let di = deleteItems.length - 1; di >= 0; di--) {\n      const deleteItem = deleteItems[di]\n      // start with merging the item next to the last deleted item\n      const mostRightIndexToCheck = math.min(structs.length - 1, 1 + findIndexSS(structs, deleteItem.clock + deleteItem.len - 1))\n      for (\n        let si = mostRightIndexToCheck, struct = structs[si];\n        si > 0 && struct.id.clock >= deleteItem.clock;\n        struct = structs[--si]\n      ) {\n        tryToMergeWithLeft(structs, si)\n      }\n    }\n  })\n}\n\n/**\n * @param {DeleteSet} ds\n * @param {StructStore} store\n * @param {function(Item):boolean} gcFilter\n */\nexport const tryGc = (ds, store, gcFilter) => {\n  tryGcDeleteSet(ds, store, gcFilter)\n  tryMergeDeleteSet(ds, store)\n}\n\n/**\n * @param {Array<Transaction>} transactionCleanups\n * @param {number} i\n */\nconst cleanupTransactions = (transactionCleanups, i) => {\n  if (i < transactionCleanups.length) {\n    const transaction = transactionCleanups[i]\n    const doc = transaction.doc\n    const store = doc.store\n    const ds = transaction.deleteSet\n    const mergeStructs = transaction._mergeStructs\n    try {\n      sortAndMergeDeleteSet(ds)\n      transaction.afterState = getStateVector(transaction.doc.store)\n      doc.emit('beforeObserverCalls', [transaction, doc])\n      /**\n       * An array of event callbacks.\n       *\n       * Each callback is called even if the other ones throw errors.\n       *\n       * @type {Array<function():void>}\n       */\n      const fs = []\n      // observe events on changed types\n      transaction.changed.forEach((subs, itemtype) =>\n        fs.push(() => {\n          if (itemtype._item === null || !itemtype._item.deleted) {\n            itemtype._callObserver(transaction, subs)\n          }\n        })\n      )\n      fs.push(() => {\n        // deep observe events\n        transaction.changedParentTypes.forEach((events, type) =>\n          fs.push(() => {\n            // We need to think about the possibility that the user transforms the\n            // Y.Doc in the event.\n            if (type._item === null || !type._item.deleted) {\n              events = events\n                .filter(event =>\n                  event.target._item === null || !event.target._item.deleted\n                )\n              events\n                .forEach(event => {\n                  event.currentTarget = type\n                })\n              // sort events by path length so that top-level events are fired first.\n              events\n                .sort((event1, event2) => event1.path.length - event2.path.length)\n              // We don't need to check for events.length\n              // because we know it has at least one element\n              callEventHandlerListeners(type._dEH, events, transaction)\n            }\n          })\n        )\n        fs.push(() => doc.emit('afterTransaction', [transaction, doc]))\n      })\n      callAll(fs, [])\n    } finally {\n      // Replace deleted items with ItemDeleted / GC.\n      // This is where content is actually remove from the Yjs Doc.\n      if (doc.gc) {\n        tryGcDeleteSet(ds, store, doc.gcFilter)\n      }\n      tryMergeDeleteSet(ds, store)\n\n      // on all affected store.clients props, try to merge\n      transaction.afterState.forEach((clock, client) => {\n        const beforeClock = transaction.beforeState.get(client) || 0\n        if (beforeClock !== clock) {\n          const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client))\n          // we iterate from right to left so we can safely remove entries\n          const firstChangePos = math.max(findIndexSS(structs, beforeClock), 1)\n          for (let i = structs.length - 1; i >= firstChangePos; i--) {\n            tryToMergeWithLeft(structs, i)\n          }\n        }\n      })\n      // try to merge mergeStructs\n      // @todo: it makes more sense to transform mergeStructs to a DS, sort it, and merge from right to left\n      //        but at the moment DS does not handle duplicates\n      for (let i = 0; i < mergeStructs.length; i++) {\n        const { client, clock } = mergeStructs[i].id\n        const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client))\n        const replacedStructPos = findIndexSS(structs, clock)\n        if (replacedStructPos + 1 < structs.length) {\n          tryToMergeWithLeft(structs, replacedStructPos + 1)\n        }\n        if (replacedStructPos > 0) {\n          tryToMergeWithLeft(structs, replacedStructPos)\n        }\n      }\n      if (!transaction.local && transaction.afterState.get(doc.clientID) !== transaction.beforeState.get(doc.clientID)) {\n        logging.print(logging.ORANGE, logging.BOLD, '[yjs] ', logging.UNBOLD, logging.RED, 'Changed the client-id because another client seems to be using it.')\n        doc.clientID = generateNewClientId()\n      }\n      // @todo Merge all the transactions into one and provide send the data as a single update message\n      doc.emit('afterTransactionCleanup', [transaction, doc])\n      if (doc._observers.has('update')) {\n        const encoder = new UpdateEncoderV1()\n        const hasContent = writeUpdateMessageFromTransaction(encoder, transaction)\n        if (hasContent) {\n          doc.emit('update', [encoder.toUint8Array(), transaction.origin, doc, transaction])\n        }\n      }\n      if (doc._observers.has('updateV2')) {\n        const encoder = new UpdateEncoderV2()\n        const hasContent = writeUpdateMessageFromTransaction(encoder, transaction)\n        if (hasContent) {\n          doc.emit('updateV2', [encoder.toUint8Array(), transaction.origin, doc, transaction])\n        }\n      }\n      const { subdocsAdded, subdocsLoaded, subdocsRemoved } = transaction\n      if (subdocsAdded.size > 0 || subdocsRemoved.size > 0 || subdocsLoaded.size > 0) {\n        subdocsAdded.forEach(subdoc => {\n          subdoc.clientID = doc.clientID\n          if (subdoc.collectionid == null) {\n            subdoc.collectionid = doc.collectionid\n          }\n          doc.subdocs.add(subdoc)\n        })\n        subdocsRemoved.forEach(subdoc => doc.subdocs.delete(subdoc))\n        doc.emit('subdocs', [{ loaded: subdocsLoaded, added: subdocsAdded, removed: subdocsRemoved }, doc, transaction])\n        subdocsRemoved.forEach(subdoc => subdoc.destroy())\n      }\n\n      if (transactionCleanups.length <= i + 1) {\n        doc._transactionCleanups = []\n        doc.emit('afterAllTransactions', [doc, transactionCleanups])\n      } else {\n        cleanupTransactions(transactionCleanups, i + 1)\n      }\n    }\n  }\n}\n\n/**\n * Implements the functionality of `y.transact(()=>{..})`\n *\n * @param {Doc} doc\n * @param {function(Transaction):void} f\n * @param {any} [origin=true]\n *\n * @function\n */\nexport const transact = (doc, f, origin = null, local = true) => {\n  const transactionCleanups = doc._transactionCleanups\n  let initialCall = false\n  if (doc._transaction === null) {\n    initialCall = true\n    doc._transaction = new Transaction(doc, origin, local)\n    transactionCleanups.push(doc._transaction)\n    if (transactionCleanups.length === 1) {\n      doc.emit('beforeAllTransactions', [doc])\n    }\n    doc.emit('beforeTransaction', [doc._transaction, doc])\n  }\n  try {\n    f(doc._transaction)\n  } finally {\n    if (initialCall) {\n      const finishCleanup = doc._transaction === transactionCleanups[0]\n      doc._transaction = null\n      if (finishCleanup) {\n        // The first transaction ended, now process observer calls.\n        // Observer call may create new transactions for which we need to call the observers and do cleanup.\n        // We don't want to nest these calls, so we execute these calls one after\n        // another.\n        // Also we need to ensure that all cleanups are called, even if the\n        // observes throw errors.\n        // This file is full of hacky try {} finally {} blocks to ensure that an\n        // event can throw errors and also that the cleanup is called.\n        cleanupTransactions(transactionCleanups, 0)\n      }\n    }\n  }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA,mCAAAA,SAAA;AAAA,QAAI,UAAU;AAAA,MACZ,QAAQ;AAAA,MACR,aAAa,OAAK,EAAE,MAAM,EAAE,OAAO,EAAE,QAAQ,EAAE;AAAA,MAC/C,cAAc,KAAK;AAAA,IACrB;AAEA,aAAS,WAAW,SAAS;AAC3B,aAAO,OAAO,SAAS,OAAO;AAAA,IAChC;AAEA,aAAS,MAAM,MAAM,GAAG,GAAG;AACzB,UAAI,GAAG;AACL,cAAM,KAAK,OAAO,CAAC;AACnB,YAAI;AAAI,cAAI,IAAI;AAAA,MAClB;AACA,aAAO,YAAY,MAAM,CAAC;AAAA,IAC5B;AAEA,aAAS,WAAW,KAAK;AACvB,aAAO,OAAO,OAAQ,aAAa,IAAI,QAAQ,GAAG,MAAM,MAAM,IAAI,QAAQ,GAAG,MAAM,MACjF,IAAI,QAAQ,MAAM,IAAI,EAAE,QAAQ,OAAO,IAAI,IAC3C;AAAA,IACJ;AAEA,aAAS,WAAW,KAAK;AACvB,aAAO,OAAO,OAAQ,aAAa,IAAI,QAAQ,IAAI,MAAM,MAAM,IAAI,QAAQ,IAAI,MAAM,MACnF,IAAI,QAAQ,OAAO,GAAG,EAAE,QAAQ,OAAO,GAAG,IAC1C;AAAA,IACJ;AAEA,aAAS,YAAY,MAAM;AACzB,aAAO,KAAK,MAAM,GAAG,EAAE,IAAI,OAAK,WAAW,CAAC,CAAC;AAAA,IAC/C;AAEA,aAAS,YAAY,MAAM,GAAG;AAC5B,UAAI,WAAW,CAAC;AAChB,aAAO,CAAC,MAAM,CAAC,EAAE,OAAO,OAAK,KAAK,MAAS,EAAE,KAAK,GAAG,EAAE,QAAQ,MAAM,GAAG;AAAA,IAC1E;AAEA,aAAS,QAAQ,GAAG;AAClB,UAAI,MAAM,QAAQ,CAAC;AAAG,eAAO;AAC7B,UAAI,MAAM;AAAM,eAAO;AACvB,aAAO,OAAO;AAAA,IAChB;AAEA,aAAS,aAAa,GAAG;AACvB,YAAM,IAAI,QAAQ,CAAC;AACnB,aAAO,MAAM,YAAY,MAAM,UAAU,MAAM,aAAa,KAAK;AAAA,IACnE;AAEA,aAAS,OAAO,GAAG;AACjB,YAAM,OAAO,QAAQ,CAAC;AACtB,UAAI,QAAQ,SAAS;AACnB,cAAM,MAAM,MAAM,EAAE,MAAM;AAC1B,iBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,cAAI,KAAK,OAAO,EAAE,EAAE;AAAA,QACtB;AACA,eAAO;AAAA,MACT,WAAW,QAAQ,UAAU;AAC3B,YAAI,EAAE,QAAQ;AACZ,iBAAO,EAAE,OAAO;AAAA,QAClB,OAAO;AACL,gBAAM,MAAM,CAAC;AACb,qBAAW,KAAK,GAAG;AACjB,gBAAI,KAAK,OAAO,EAAE,EAAE;AAAA,UACtB;AACA,iBAAO;AAAA,QACT;AAAA,MACF,WAAW,aAAa,CAAC,GAAG;AAC1B,cAAM,WAAW,OAAO,KAAK;AAC7B,YAAI,UAAU;AACZ,cAAI,SAAS,CAAC,GAAG;AACf,mBAAO;AAAA,UACT,OAAO;AACL,mBAAO;AAAA,UACT;AAAA,QACF,OAAO;AACL,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAEA,aAAS,WAAW,GAAG,GAAG;AACxB,UAAI,aAAa,CAAC,GAAG;AACnB,eAAO,MAAM;AAAA,MACf,WAAW,QAAQ,CAAC,KAAK,UAAU;AACjC,eAAO,OAAO,CAAC,MAAM,OAAO,CAAC;AAAA,MAC/B,WAAW,QAAQ,CAAC,KAAK,SAAS;AAChC,cAAM,IAAI,MAAM,gCAAgC;AAAA,MAClD;AAAA,IACF;AAEA,aAAS,OAAO,GAAG;AACjB,UAAI,QAAQ,CAAC,KAAK,UAAU;AAC1B,cAAM,KAAK,QAAQ,YAAY,CAAC;AAChC,YAAI,MAAM;AAAW,iBAAO;AAC5B,YAAI,QAAQ,QAAQ;AAClB,gBAAM,IAAI,MAAM,+BAA+B,EAAE,OAAO,EAAE,CAAC;AAAA,QAC7D;AACA,eAAO,KAAK,QAAQ,CAAC,CAAC;AAAA,MACxB,OAAO;AACL,eAAO;AAAA,MACT;AAAA,IACF;AAEA,aAAS,IAAI,IAAI,MAAM,OAAO;AAC5B,YAAM,YAAY,EAAE,IAAI,KAAK;AAC7B,aAAO,OAAO,WAAW,KAAK;AAC9B,aAAO;AAAA,IACT;AAEA,aAAS,QAAQ,GAAG;AAClB,UAAI,QAAQ,CAAC,KAAK,SAAS;AACzB,eAAO,IAAI,EAAE,IAAI,OAAO,EAAE,KAAK,GAAG;AAAA,MACpC,WAAW,QAAQ,CAAC,KAAK,UAAU;AACjC,eAAO,IAAI,OAAO,KAAK,CAAC,EAAE,KAAK,EAAE,IAAI,OACnC,GAAG,KAAK,UAAU,CAAC,KAAK,QAAQ,EAAE,EAAE,GAAG,EAAE,KAAK,GAAG;AAAA,MACrD,OAAO;AACL,eAAO,KAAK,UAAU,CAAC;AAAA,MACzB;AAAA,IACF;AAEA,aAAS,KAAK,KAAK;AACjB,aAAO,KAAK,IAAI,CAAC,EAAE,OAAO,KAAK,KAAK,CAAC,GAAG,GAAG,GAAG,OAAO,KAAK,KAAK,IAAI,EAAE,WAAW,CAAC,GAAG,CAAC,CAAC;AAAA,IACxF;AAEA,aAAS,KAAK,GAAG;AACf,aAAO,KAAK,QAAQ,CAAC,CAAC;AAAA,IACxB;AAEA,IAAAA,QAAO,UAAU;AAAA,MACf;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA;AAAA;;;AC/IA;AAAA,gCAAAC,SAAA;AAAA,QAAM,EAAE,OAAO,SAAS,cAAc,QAAQ,YAAY,QAAQ,KAAK,QAAQ,IAAI;AAGnF,aAAS,KAAK,MAAM,OAAO;AAEzB,YAAM,OAAO,QAAQ,IAAI;AAEzB,UAAI,SAAS,QAAQ,KAAK,GAAG;AAC3B,cAAM,IAAI,MAAM,4BAA4B;AAAA,MAC9C;AAEA,UAAI,QAAQ,SAAS;AACnB,eAAO,UAAU,MAAM,KAAK;AAAA,MAC9B,WAAW,QAAQ,UAAU;AAC3B,eAAO,WAAW,MAAM,KAAK;AAAA,MAC/B,WAAW,aAAa,IAAI,GAAG;AAC7B,eAAO,cAAc,MAAM,KAAK;AAAA,MAClC,OAAO;AACL,cAAM,IAAI,MAAM,kBAAkB;AAAA,MACpC;AAAA,IAEF;AAEA,aAAS,cAAc,GAAG,GAAG,OAAK,KAAK;AACrC,UAAI,MAAM,GAAG;AACX,eAAO,CAAC,IAAI,WAAW,MAAM,IAAI,GAAG,EAAE,OAAO,GAAI,OAAO,EAAG,CAAC,CAAC;AAAA,MAC/D,OAAO;AACL,eAAO,CAAC;AAAA,MACV;AAAA,IACF;AAEA,aAAS,UAAU,GAAG,GAAG,OAAK,KAAK;AAEjC,YAAM,OAAO,CAAC;AACd,YAAM,OAAO,CAAC;AAEd,YAAM,OAAO,CAAC;AAEd,eAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,iBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,cAAI,KAAK;AAAM;AACf,cAAI,KAAK;AAAM;AACf,cACG,CAAC,QAAQ,UAAU,QAAQ,EAAE,EAAE,KAAK,WAAW,QAAQ,EAAE,EAAE,KAAK,WAAW,KAAK,KACjF,WAAW,EAAE,IAAI,EAAE,EAAE,GACrB;AACA,iBAAK,KAAK;AACV,iBAAK,KAAK;AAAA,UACZ;AAAA,QACF;AAAA,MACF;AAEA,YAAM,MAAM,CAAC;AAEb,eAAS,IAAI,GAAG,IAAI,GAAG,IAAI,EAAE,UAAU,IAAI,EAAE,UAAS;AAEpD,YAAI,KAAK,KAAK,KAAK,KAAK,KAAK,MAAM,GAAG;AAEpC,cAAI,QAAQ,EAAE,EAAE,MAAM,UAAU;AAC9B,gBAAI,KAAK,GAAG,WAAW,EAAE,IAAI,EAAE,IAAI,MAAM,MAAM,GAAG,EAAE,EAAE,CAAC,CAAC;AAAA,UAC1D;AACA;AACA;AACA;AAAA,QACF;AAEA,YAAI,IAAI,EAAE,UAAU,EAAE,KAAK,OAAO;AAChC,cAAI,KAAK,IAAI,UAAU,MAAM,MAAM,GAAG,EAAE,EAAE,GAAG,EAAE,OAAO,EAAE,GAAG,CAAC,CAAC;AAC7D;AACA;AAAA,QACF;AAEA,YAAI,IAAI,EAAE,UAAU,EAAE,KAAK,OAAO;AAChC,eAAK,QAAQ,IAAI,OAAO,MAAM,MAAM,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,OAAO,EAAE,GAAG,CAAC,CAAC;AAClE;AACA;AAAA,QACF;AAEA,YAAI,IAAI,EAAE,UAAU,KAAK,MAAM;AAC7B,gBAAM,OAAO,MAAM,MAAM,KAAK,IAAI,EAAE,KAAK,GAAG;AAC5C,gBAAM,KAAK,MAAM,MAAM,CAAC;AACxB,cAAI,MAAM,MAAM;AACd,gBAAI,KAAK,EAAE,IAAI,QAAQ,MAAM,MAAM,GAAG,CAAC;AACvC,gBAAI,QAAQ,KAAK,EAAE,KAAK,UAAU;AAChC,kBAAI,KAAK,GAAG,WAAW,EAAE,KAAK,KAAK,EAAE,IAAI,IAAI,CAAC;AAAA,YAChD;AAAA,UACF;AACA;AACA;AACA;AAAA,QACF;AAEA,cAAM,IAAI,MAAM,sBAAsB;AAAA,MACxC;AAEA,aAAO,IAAI,OAAO,IAAI;AAAA,IACxB;AAGA,aAAS,WAAW,GAAG,GAAG,OAAK,KAAK,KAAK;AAEvC,YAAM,MAAM,CAAC;AAEb,YAAM,QAAQ,OAAO,KAAK,CAAC;AAC3B,YAAM,OAAO,MAAM;AACnB,UAAI,WAAW;AAEf,eAAS,IAAI,GAAG,IAAI,MAAM,KAAI;AAE5B,cAAM,IAAI,MAAM;AAChB,YAAI,CAAE,EAAE,eAAe,CAAC,GAAI;AAC1B;AACA,cAAI,KAAK,EAAE,IAAI,UAAU,MAAM,MAAM,MAAM,CAAC,GAAG,OAAO,OAAO,EAAE,EAAE,EAAE,CAAC;AACpE;AAAA,QACF;AAEA,YAAI,EAAE,OAAO,EAAE;AAAI;AAEnB,cAAM,OAAO,QAAQ,EAAE,EAAE;AAEzB,YAAI,aAAa,EAAE,EAAE,GAAG;AACtB,cAAI,KAAK,GAAG,cAAc,EAAE,IAAI,EAAE,IAAI,MAAM,MAAM,CAAC,GAAG,GAAG,CAAC;AAAA,QAC5D,WAAW,SAAS,QAAQ,EAAE,EAAE,GAAG;AACjC,cAAI,KAAK,EAAE,IAAI,WAAW,MAAM,MAAM,MAAM,CAAC,GAAG,OAAO,OAAO,EAAE,EAAE,GAAG,OAAO,OAAO,EAAE,EAAE,EAAE,CAAC;AAAA,QAC5F,WAAW,SAAS,SAAS;AAC3B,cAAI,KAAK,GAAG,UAAU,EAAE,IAAI,EAAE,IAAI,MAAM,MAAM,CAAC,CAAC,CAAC;AAAA,QACnD,WAAW,SAAS,UAAU;AAC5B,cAAI,KAAK,GAAG,WAAW,EAAE,IAAI,EAAE,IAAI,MAAM,MAAM,CAAC,GAAG,GAAG,CAAC;AAAA,QACzD;AAAA,MACF;AAEA,YAAM,QAAQ,OAAO,KAAK,CAAC;AAC3B,YAAM,OAAO,MAAM;AAEnB,UAAI,OAAO,OAAO,UAAU;AAC1B,iBAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,gBAAM,IAAI,MAAM;AAChB,cAAI,CAAE,EAAE,eAAe,CAAC,GAAI;AAC1B,gBAAI,KAAK,EAAE,IAAI,OAAO,MAAM,MAAM,MAAM,CAAC,GAAG,OAAO,OAAO,EAAE,EAAE,EAAE,CAAC;AAAA,UACnE;AAAA,QACF;AAAA,MACF;AAEA,aAAO;AAAA,IACT;AAGA,IAAAA,QAAO,UAAU;AAAA;AAAA;;;ACnJjB;AAAA,iCAAAC,SAAA;AAAA,QAAM,EAAE,SAAS,QAAQ,QAAQ,YAAY,IAAI;AAGjD,aAAS,MAAM,MAAM,SAAS;AAE5B,gBAAU,OAAO,OAAO;AACxB,YAAM,YAAY,CAAC;AACnB,UAAI,QAAQ;AAEZ;AACA,mBAAW,CAAC,IAAI,MAAM,KAAK,QAAQ,QAAQ,GAAG;AAE5C,gBAAM,aAAa,YAAY,OAAO,IAAI;AAC1C,gBAAM,OAAO,WAAW,MAAM;AAC9B,cAAI,MAAM,WAAW,IAAI;AAEzB,cAAI,OAAO;AAEX,qBAAW,KAAK,YAAY;AAC1B,gBAAI,CAAC,MAAM;AACT,wBAAU,KAAK,MAAM;AACrB,uBAAS;AAAA,YACX;AACA,kBAAMC,OAAM,KAAK,CAAC;AAClB,gBAAIA,MAAK;AACP,qBAAO,KAAK,KAAK,OAAK,OAAO,CAAC,KAAKA,IAAG;AAAA,YACxC,OAAO;AACL,qBAAO,KAAK;AAAA,YACd;AAAA,UACF;AAEA,gBAAM,MAAM,KAAK,GAAG;AACpB,cAAI,KAAK;AACP,kBAAM,MAAM,KAAK,UAAU,OAAK,OAAO,CAAC,KAAK,GAAG;AAChD,gBAAI,CAAC,KAAK;AACR,oBAAM;AAAA,YACR,OAAO;AACL,wBAAU,KAAK,MAAM;AAAA,YACvB;AAAA,UACF;AAEA,gBAAM,OAAO,QAAQ,IAAI;AAEzB,cAAI,OAAO,MAAM,WAAW;AAC1B,iBAAK,OAAO,OAAO,OAAO,KAAK;AAAA,UACjC,WAAW,OAAO,MAAM,QAAQ;AAC9B,oBAAQ,CAAC;AACT,kBAAM,MAAM;AAAA,cACV,EAAE,IAAI,UAAU,MAAM,OAAO,KAAK;AAAA,cAClC,EAAE,IAAI,OAAO,MAAM,OAAO,MAAM,OAAO,MAAM;AAAA,YAC/C;AACA,oBAAQ,OAAO,KAAK,GAAG,GAAG,GAAG,GAAG;AAAA,UAClC,WAAW,OAAO,MAAM,UAAU;AAChC,gBAAI,QAAQ,UAAU;AACpB,wBAAU,MAAM,QAAQ,OAAO,KAAK,IAAI;AACxC,qBAAO,KAAK;AAAA,YACd,WAAW,QAAQ,SAAS;AAC1B,oBAAM,QAAQ,KAAK,OAAO,KAAK,CAAC;AAChC,wBAAU,CAAE,MAAM,KAAM,IAAI;AAAA,YAC9B;AAAA,UACF,WAAW,OAAO,MAAM,OAAO;AAC7B,gBAAI,QAAQ,UAAU;AACpB,mBAAK,OAAO,OAAO,OAAO,KAAK;AAAA,YACjC,WAAW,QAAQ,SAAS;AAC1B,kBAAI,SAAS,OAAO,UAAU,OAAO;AACnC,qBAAK,OAAO,KAAK,GAAG,MAAM,KAAK;AAC/B,wBAAQ;AAAA,cACV,OAAO;AACL,qBAAK,OAAO,KAAK,GAAG,OAAO,OAAO,KAAK,CAAC;AAAA,cAC1C;AAAA,YACF;AAAA,UACF;AAAA,QACF;AACA,aAAO;AAAA,IACT;AAGA,aAAS,KAAK,GAAG;AACf,UAAI,MAAM;AAAW;AACrB,YAAM,IAAI,EAAE,MAAM,YAAY;AAC9B,UAAI;AAAG,eAAO,EAAE;AAAA,IAClB;AAEA,IAAAD,QAAO,UAAU;AAAA;AAAA;;;ACnFjB;AAAA,mCAAAE,SAAA;AAAA,QAAM,EAAE,QAAQ,OAAO,IAAI;AAE3B,aAAS,QAAQ,SAAS;AAExB,YAAM,WAAW,OAAO,OAAO,EAAE,QAAQ;AAEzC,iBAAW,UAAU,UAAU;AAE7B,YAAI,OAAO,MAAM,OAAO;AACtB,iBAAO,KAAK;AACZ,gBAAM,KAAK,OAAO,OAAO,KAAK;AAC9B,cAAI,IAAI;AACN,mBAAO,SAAS,OAAO,KAAK,MAAM,GAAG,EAAE,IAAI;AAC3C,mBAAO,OAAO,OAAO,KAAK,QAAQ,QAAQ,IAAI,KAAK;AAAA,UACrD;AAAA,QAEF,WAAW,OAAO,MAAM,UAAU;AAChC,iBAAO,KAAK;AAAA,QACd;AAEA,YAAI,WAAW,QAAQ;AACrB,cAAI,QAAQ,OAAO;AAAA,QACrB;AAEA,YAAI,WAAW,QAAQ;AACrB,cAAI,SAAS,OAAO;AAAA,QACtB;AAEA,YAAI,UAAU,QAAW;AACvB,iBAAO,OAAO;AAAA,QAChB,OAAO;AACL,iBAAO,QAAQ;AAAA,QACjB;AAEA,YAAI,WAAW,QAAW;AACxB,iBAAO,OAAO;AAAA,QAChB,OAAO;AACL,iBAAO,QAAQ;AAAA,QACjB;AAAA,MAEF;AAEA,aAAO;AAAA,IAET;AAEA,IAAAA,QAAO,UAAU;AAAA;AAAA;;;AC9CjB;AAAA,gCAAAC,SAAA;AAAA,QAAM,SAAS,QAAQ;AACvB,QAAM,OAAO;AACb,QAAM,QAAQ;AACd,QAAM,UAAU;AAChB,QAAM,EAAE,QAAQ,MAAM,YAAY,QAAQ,IAAI;AAE9C,QAAI,iBAAiB;AAErB,QAAM,OAAO,oBAAI,QAAQ;AACzB,QAAM,OAAO,IAAI;AAEjB,QAAM,aAAN,MAAiB;AAAA,MAEf,cAAc;AACZ,aAAK,IAAI,MAAM;AAAA,UACb,SAAS,CAAC;AAAA,UACV,OAAO,CAAC;AAAA,UACR,SAAS;AAAA,UACT,MAAM,CAAC;AAAA,QACT,CAAC;AAAA,MACH;AAAA,MAEA,OAAO,KAAK,MAAM,MAAI,MAAM;AAC1B,YAAI,MAAM,IAAI,WAAW;AACzB,aAAK,IAAI,GAAG,EAAE,MAAM;AACpB,cAAM,WAAW,OAAO,KAAK,CAAAC,SAAO,OAAO,OAAOA,MAAK,IAAI,CAAC;AAC5D,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,OAAO,MAAM,MAAI,MAAM;AAC5B,YAAI,MAAM,IAAI,WAAW;AACzB,aAAK,IAAI,GAAG,EAAE,MAAM;AACpB,eAAO,OAAO,KAAK,OAAO,IAAI,CAAC;AAC/B,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,MAAM,KAAK;AAChB,YAAI,QAAQ,IAAI,WAAW;AAC3B,aAAK,IAAI,OAAO,KAAK,IAAI,GAAG,CAAC;AAC7B,eAAO,OAAO,OAAO,GAAG;AACxB,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,OAAO;AACZ,eAAO,WAAW,KAAK,CAAC,CAAC;AAAA,MAC3B;AAAA,MAEA,OAAO,MAAM,KAAK,gBAAc,gBAAgB;AAC9C,cAAM,QAAQ,WAAW,OAAO,GAAG;AACnC,aAAK,IAAI,KAAK,EAAE,UAAU,KAAK,IAAI,GAAG,EAAE;AACxC,aAAK,IAAI,KAAK,EAAE,OAAO,OAAO,KAAK,IAAI,GAAG,EAAE,IAAI;AAChD,mBAAW,aAAa,KAAK,IAAI,KAAK,GAAG,aAAa;AACtD,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,aAAaC,OAAM,eAAe;AACvC,cAAM,mBAAmBA,MAAK,QAAQ;AACtC,YAAI,mBAAmB,eAAe;AACpC,gBAAM,gBAAgBA,MAAK,QAAQ,MAAM,GAAG,mBAAmB,aAAa;AAC5E,qBAAW,QAAQ,eAAe;AAChC,mBAAOA,MAAK,KAAK,KAAK;AAAA,UACxB;AAAA,QACF;AACA,QAAAA,MAAK,UAAUA,MAAK,QAAQ,MAAM,CAAC,aAAa;AAAA,MAClD;AAAA,MAEA,OAAO,WAAW,MAAM,OAAO;AAC7B,cAAM,QAAQ,KAAK,MAAM,KAAK;AAC9B,cAAM,UAAU;AAAA,UACd,MAAM;AAAA,UACN,KAAK,KAAK,IAAI,IAAI,EAAE;AAAA,UACpB,IAAI,QAAQ,aAAa;AAAA,UACzB,KAAK,KAAK;AAAA,UACV,KAAK,IAAI;AAAA,QACX;AACA,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,cAAc,KAAK,IAAI,KAAK;AAEjC,cAAM,EAAE,QAAQ,IAAI,KAAK,IAAI,GAAG;AAEhC,eAAO,MAAM;AACX,cAAI,QAAQ,UAAU;AAAG;AACzB,gBAAM,SAAS,QAAQ,QAAQ,SAAS;AACxC,cAAI,OAAO,KAAK,MAAO,OAAO,MAAM,MAAM,OAAO,MAAM,KAAM;AAC3D,kBAAM,IAAI,KAAK,IAAI,GAAG,EAAE,QAAQ,IAAI;AACpC,kBAAM,KAAK,QAAQ,EAAE,IAAI,CAAC;AAC1B,mBAAO,KAAK,IAAI,GAAG,EAAE,KAAK,EAAE;AAC5B,iBAAK,IAAI,GAAG,EAAE,MAAM,KAAK,CAAC;AAC1B;AAAA,UACF;AACA;AAAA,QACF;AAAA,MACF;AAAA,MAEA,OAAO,mBAAmB,KAAK;AAC7B,cAAM,EAAE,OAAO,QAAQ,IAAI,KAAK,IAAI,GAAG;AACvC,YAAI;AACJ,eAAO,SAAS,MAAM,IAAI,GAAG;AAC3B,gBAAM,KAAK,OAAO,IAAI;AACtB,eAAK,IAAI,GAAG,EAAE,KAAK,OAAO,OAAO;AACjC,kBAAQ,KAAK,MAAM;AAAA,QACrB;AAAA,MACF;AAAA,MAEA,OAAO,oBAAoB,KAAK,SAAS;AACvC,eAAO,WAAW,aAAa,KAAK,SAAS,IAAI;AAAA,MACnD;AAAA,MAEA,OAAO,aAAa,KAAK,SAAS,SAAS;AACzC,aAAK,IAAI,GAAG,EAAE,UAAU;AACxB,cAAM,SAAS,UAAU,MAAM,WAAW,MAAM,GAAG;AACnD,YAAI,KAAK,IAAI,GAAG,EAAE,KAAK,QAAQ,MAAM;AACnC,iBAAO;AAAA,QACT;AACA,YAAI;AACF,qBAAW,cAAc,QAAQ,QAAQ,IAAI,QAAQ,GAAG;AAAA,QAC1D,SAAS,GAAP;AACA,eAAK,IAAI,MAAM,EAAE,UAAU,oBAAoB;AAAA,QACjD;AACA,YAAI;AACF,gBAAM,QAAQ,QAAQ,IAAI;AAC1B,eAAK,IAAI,MAAM,EAAE,KAAK,QAAQ,OAAO;AAAA,QACvC,SAAS,GAAP;AACA,eAAK,IAAI,MAAM,EAAE,UAAU,mBAAmB;AAAA,QAChD;AACA,YAAI;AACF,qBAAW,mBAAmB,MAAM;AAAA,QACtC,SAAS,GAAP;AACA,eAAK,IAAI,MAAM,EAAE,UAAU,qBAAqB;AAAA,QAClD;AACA,cAAM,UAAU,KAAK,IAAI,MAAM,EAAE;AACjC,YAAI,MAAM,QAAQ;AAClB,eAAO,MAAM,KAAK,QAAQ,MAAM,GAAG,KAAK,QAAQ;AAAI;AACpD,gBAAQ,OAAO,KAAK,GAAG,OAAO;AAC9B,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,OAAO,KAAK,IAAI;AAErB,eAAO,eAAe,UAAU;AAChC,eAAO,cAAc,QAAQ;AAE7B,cAAM,MAAM,OAAO,GAAG;AACtB,WAAG,GAAG;AACN,cAAM,UAAU,WAAW,WAAW,KAAK,GAAG;AAC9C,eAAO,WAAW,aAAa,KAAK,OAAO;AAAA,MAC7C;AAAA,MAEA,OAAO,WAAW,KAAK;AACrB,eAAO,KAAK,IAAI,GAAG,EAAE;AAAA,MACvB;AAAA,MAEA,OAAO,MAAM,MAAM,MAAM;AACvB,YAAI,MAAM,WAAW,KAAK,CAAC,CAAC;AAC5B,cAAM,WAAW,WAAW,WAAW,IAAI;AAC3C,cAAM,WAAW,WAAW,WAAW,IAAI;AAC3C,cAAM,UAAU,CAAC;AACjB,eAAO,SAAS,UAAU,SAAS,QAAQ;AACzC,cAAI,CAAC,SAAS,QAAQ;AACpB,oBAAQ,KAAK,SAAS,MAAM,CAAC;AAAA,UAE/B,WAAW,CAAC,SAAS,QAAQ;AAC3B,oBAAQ,KAAK,SAAS,MAAM,CAAC;AAAA,UAE/B,WAAW,SAAS,GAAG,QAAQ,SAAS,GAAG,KAAK;AAC9C,oBAAQ,KAAK,SAAS,MAAM,KAAK,SAAS,MAAM,CAAC;AAAA,UAEnD,WAAW,SAAS,GAAG,KAAK,SAAS,GAAG,IAAI;AAC1C,oBAAQ,KAAK,SAAS,MAAM,CAAC;AAAA,UAE/B,WAAW,SAAS,GAAG,MAAM,SAAS,GAAG,IAAI;AAE3C,gBAAI,SAAS,GAAG,MAAM,SAAS,GAAG,KAAK;AACrC,sBAAQ,KAAK,SAAS,MAAM,CAAC;AAAA,YAC/B,OAAO;AACL,sBAAQ,KAAK,SAAS,MAAM,CAAC;AAAA,YAC/B;AAAA,UAEF,OAAO;AACL,oBAAQ,KAAK,SAAS,MAAM,CAAC;AAAA,UAC/B;AAAA,QACF;AAEA,mBAAW,KAAK,SAAS;AACvB,gBAAM,WAAW,aAAa,KAAK,CAAC;AAAA,QACtC;AACA,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,WAAW,KAAK;AACrB,eAAO,KAAK,IAAI,GAAG,EAAE;AAAA,MACvB;AAAA,MAEA,OAAO,eAAe,KAAK;AACzB,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,iBAAiB,KAAK;AAC3B,yBAAiB;AAAA,MACnB;AAAA,MAEA,OAAO,aAAa,IAAI;AACtB,gBAAQ,eAAe;AAAA,MACzB;AAAA,MAEA,OAAO,IAAI,KAAK;AACd,eAAO,KAAK,GAAG;AAAA,MACjB;AAAA,MAEA,OAAO,KAAK,KAAK,gBAAc,gBAAgB;AAC7C,cAAM,EAAE,MAAM,OAAO,KAAK,IAAI,KAAK,MAAM,GAAG;AAC5C,mBAAW,aAAa,OAAO,aAAa;AAC5C,cAAM,MAAM,WAAW,KAAK,IAAI;AAChC,eAAO,OAAO,KAAK,IAAI,GAAG,GAAG,KAAK;AAClC,eAAO;AAAA,MACT;AAAA,MAEA,OAAO,KAAK,KAAK;AACf,cAAM,EAAE,QAAQ,MAAM,IAAI,KAAK,IAAI,GAAG;AACtC,eAAO,KAAK,UAAU;AAAA,UACpB,MAAM;AAAA,UACN,MAAM;AAAA,QACR,CAAC;AAAA,MACH;AAAA,MAEA,OAAO,UAAU,SAAS;AACxB,mBAAW,OAAO;AAAA,MACpB;AAAA,IACF;AAEA,aAAS,MAAM;AACb,aAAO,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC;AAAA,IAC/C;AAEA,QAAI,MAAM;AACV,aAAS,OAAO;AACd,aAAO;AAAA,IACT;AAEA,IAAAF,QAAO,UAAU;AAAA;AAAA;;;ACjPjB;AAAA,iCAAAG,SAAA;AAAA,QAAM,OAAO;AACb,QAAM,QAAQ;AACd,QAAM,UAAU;AAChB,QAAM,OAAO;AAMb,IAAAA,QAAO,UAAU,OAAO,OAAO,MAAM,EAAE,MAAM,MAAM,OAAO,QAAQ,CAAC;AAAA;AAAA;;;ACTnE,IAAAC,cAAkG;;;ACAlG,iBAA+C;AAG/C,IAAO,qCAAQ,2CAAwD;AAAA,EACnE,YAAY;AAAA,IACR,eAAe;AAAA,MACX,gBAAgB;AAAA,QACZ,UAAU;AAAA,MACd;AAAA,IACJ;AAAA,IACA,SAAS,CAAC,YAAY;AAAA,MAClB,GAAG;AAAA,MACH,SAAS;AAAA,QACL,QAAQ;AAAA,QACR,sBAAsB;AAAA,QACtB,QAAQ;AAAA,QACR,QAAQ;AAAA,MACZ;AAAA,MACA,WAAW;AAAA,QACP,QAAQ;AAAA,QACR,wBAAwB;AAAA,MAC5B;AAAA,IACJ;AAAA,IACA,WAAW,CAAC,YAAY;AAAA,MACpB,GAAG;AAAA,IACP;AAAA,IACA,eAAe,CAAC,YAAY;AAAA,MACxB,GAAG;AAAA,IACP;AAAA,IACA,QAAQ,CAAC;AAAA,EACb;AACJ,CAAC;;;AC/BD,oBAA2C;AAC3C,qBAAgE;AAChE,uBAA6C;AAC7C,IAAAC,KAAmB;;;ACHnB,QAAmB;AAKZ,SAAS,WAAW,SAAsB,QAAkD;AAC/F,QAAM,cAAc,kBAAkB,OAAO;AAE7C,MAAI;AACA,QAAI,aAAa,OAAO,YAAY;AAAA,EACxC,SAAS,GAAP;AACE,iBAAa;AAAA,EACjB;AAEA,MAAI,eAAe,YAAY,cAAc,SAAS;AAClD,UAAM,cAAc;AACpB,UAAM,eAAe;AAErB,UAAM,SACF,aAAa,UAAU,YAAY,UACnC,YAAY,MAAM,CAAC,GAAG,MAAM,WAAW,aAAa,IAAI,CAAC,GAAG,YAAY,EAAE,CAAC;AAC/E,WAAO;AAAA,EACX,WAAW,eAAe,UAAU,cAAc,UAAU;AACxD,UAAM,YAAY;AAClB,UAAM,aAAa;AAEnB,QAAI,iBAAiB;AACrB,aAAS,aAAa,WAAW;AAC7B;AACA,UAAI,CAAC,WAAW,WAAW,IAAI,SAAS,GAAG,UAAU,UAAU,GAAG;AAC9D,eAAO;AAAA,MACX;AAAA,IACJ;AACA,WAAO,kBAAkB,MAAM,KAAK,WAAW,KAAK,CAAC,EAAE;AAAA,EAC3D,OAAO;AACH,WAAO,WAAW;AAAA,EACtB;AACJ;AAEO,SAAS,WAAW,YAAuC,WAAiD;AAC/G,MAAI,UAAU;AAEd,QAAM,cAAc,kBAAkB,UAAU;AAEhD,UAAQ,aAAa;AAAA,IACjB,KAAK;AACD,UAAI,CAAC,MAAM,QAAQ,SAAS,GAAG;AAC3B,cAAM,IAAI,MAAM,gBAAgB,yBAAyB;AAAA,MAC7D;AAEA,YAAM,eAAe;AACrB,YAAM,cAAc;AACpB,YAAM,aAAa,OAAO;AAE1B,UAAI,SAAS;AACb,eAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK;AACzC,YAAI,QAAQ;AACZ,cAAM,cAAc,YAAY;AAChC,cAAM,MAAM,aAAa,SAAS,YAAY,SAAS,aAAa,SAAS,YAAY;AACzF,iBAAS,IAAI,QAAQ,CAAC,SAAS,IAAI,KAAK,KAAK;AACzC,gBAAM,eAAe,IAAI,aAAa,SAAS,aAAa,IAAI,CAAC,IAAI;AACrE,gBAAMC,eAAc,IAAI,YAAY,SAAS,YAAY,KAAK;AAE9D,cAAI,WAAW,cAAcA,YAAW,GAAG;AACvC,qBAAS,IAAI,IAAI,GAAG,KAAK,QAAQ,KAAK;AAClC,wBAAU;AACV,2BAAa,OAAO,CAAC;AAAA,YACzB;AACA,kBAAM,eAAe,IAAI;AACzB,qBAAS,IAAI,IAAI;AACjB,oBAAQ;AAAA,UACZ;AAAA,QACJ;AACA,YAAI,CAAC,OAAO;AACR,cAAI;AACA,gBAAI,YAAY,YAAY,YAAY;AAAA,UAC5C,SAAS,GAAP;AACE,wBAAY;AAAA,UAChB;AACA,gBAAM,eAAe,SAAS,aAAa,SAAS,aAAa,IAAI,MAAM,IAAI;AAC/E,gBAAMC,eAAc,kBAAkB,YAAY;AAIlD,cACKA,gBAAe,UAAU,aAAa,YACtCA,gBAAe,YAAY,aAAa,SAC3C;AACE,uBAAW,cAAc,WAAW;AAAA,UACxC,OAAO;AACH,yBAAa,OAAO,QAAQ,CAAC,UAAU,WAAW,CAAC,CAAC;AAAA,UACxD;AAEA;AACA,oBAAU;AAAA,QACd;AAAA,MACJ;AACA,aAAO,aAAa,SAAS,YAAY,QAAQ;AAC7C,kBAAU;AACV,qBAAa,OAAO,YAAY,MAAM;AAAA,MAC1C;AAEA;AAAA,IACJ,KAAK;AACD,UAAI,UAAU,YAAY,SAAS,UAAU;AACzC,cAAM,IAAI,MAAM,gBAAgB,0BAA0B;AAAA,MAC9D;AAEA,YAAM,aAAa;AACnB,YAAM,YAAY;AAElB,iBAAW,OAAO,WAAW,KAAK,GAAG;AACjC,YAAI,EAAE,OAAO,YAAY;AAErB,qBAAW,OAAO,GAAG;AACrB,oBAAU;AACV;AAAA,QACJ;AACA,cAAM,eAAe,WAAW,IAAI,GAAG;AACvC,cAAM,cAAc,UAAU;AAE9B,cAAMA,eAAc,kBAAkB,YAAY;AAElD,YAAI;AACA,cAAI,YAAY,YAAY,YAAY;AAAA,QAC5C,SAAS,GAAP;AACE,sBAAY;AAAA,QAChB;AAEA,YACKA,gBAAe,UAAU,cAAc,YACvCA,gBAAe,YAAY,cAAc,WACzC,CAAC,CAAC,QAAQ,QAAQ,EAAE,SAASA,YAAW,KAAKA,iBAAgB,WAChE;AAEE,qBAAW,OAAO,GAAG;AACrB,oBAAU;AAAA,QACd,WAAWA,gBAAe,UAAUA,gBAAe,UAAU;AAEzD,gBAAM,eAAe,WAAW,cAAc,WAAW;AACzD,sBAAY;AAAA,QAChB,OAAO;AAEH,cAAI,iBAAiB,aAAa;AAC9B,uBAAW,IAAI,KAAK,WAAW;AAC/B,sBAAU;AAAA,UACd;AAAA,QACJ;AAAA,MACJ;AAEA,iBAAW,OAAO,WAAW;AACzB,YAAI,CAAC,WAAW,IAAI,GAAG,GAAG;AACtB,gBAAM,QAAQ,UAAU,UAAU,IAAI;AAEtC,qBAAW,IAAI,KAAK,KAAK;AACzB,oBAAU;AAAA,QACd;AAAA,MACJ;AACA;AAAA,IACJ;AACI,YAAM,IAAI,MAAM,gDAAgD,YAAY;AAAA,EACpF;AACA,SAAO;AACX;AAEA,SAAS,UAAU,OAAiB;AAChC,MAAI;AACA,QAAI,YAAY,MAAM,YAAY;AAAA,EACtC,SAAS,GAAP;AACE,gBAAY;AAAA,EAChB;AAEA,MAAI,aAAa,SAAS;AACtB,UAAM,MAAM,IAAM,QAAM;AAExB,eAAW,KAAK,KAAK;AACrB,WAAO;AAAA,EACX,WAAW,aAAa,UAAU;AAC9B,UAAMC,OAAM,IAAM,MAAI;AAEtB,eAAWA,MAAK,KAAK;AACrB,WAAOA;AAAA,EACX,OAAO;AACH,WAAO;AAAA,EACX;AACJ;AAEA,SAAS,kBAAkB,SAAsB;AAC7C,MAAI;AACA,QAAI,QAAQ,WAAW,UAAa,QAAQ,QAAQ,QAAW;AAC3D,aAAO;AAAA,IACX,WAAW,QAAQ,SAAS,UAAa,QAAQ,QAAQ,QAAW;AAChE,aAAO;AAAA,IACX,OAAO;AACH,aAAO,QAAQ,YAAY;AAAA,IAC/B;AAAA,EACJ,SAAS,GAAP;AACE,WAAO;AAAA,EACX;AACJ;;;AD7LA,oBAA0B;;;AEA1B,YAAuB;AACvB,WAAsB;AACtB,UAAqB;AACrB,eAA0B;AAC1B,eAA0B;AAmGnB,IAAM,wBAAwB,QAAM;AACzC,KAAG,QAAQ,QAAQ,UAAQ;AACzB,SAAK,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAKrC,QAAI,GAAG;AACP,SAAK,IAAI,GAAG,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACvC,YAAM,OAAO,KAAK,IAAI;AACtB,YAAM,QAAQ,KAAK;AACnB,UAAI,KAAK,QAAQ,KAAK,OAAO,MAAM,OAAO;AACxC,aAAK,MAAW,SAAI,KAAK,KAAK,MAAM,QAAQ,MAAM,MAAM,KAAK,KAAK;AAAA,MACpE,OAAO;AACL,YAAI,IAAI,GAAG;AACT,eAAK,KAAK;AAAA,QACZ;AACA;AAAA,MACF;AAAA,IACF;AACA,SAAK,SAAS;AAAA,EAChB,CAAC;AACH;AAoFO,IAAM,iBAAiB,CAAC,SAAS,OAAO;AAC7C,EAAS,sBAAa,QAAQ,aAAa,GAAG,QAAQ,IAAI;AAC1D,KAAG,QAAQ,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAQ,cAAc;AACtB,IAAS,sBAAa,QAAQ,aAAa,MAAM;AACjD,UAAM,MAAM,QAAQ;AACpB,IAAS,sBAAa,QAAQ,aAAa,GAAG;AAC9C,aAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC5B,YAAM,OAAO,QAAQ;AACrB,cAAQ,aAAa,KAAK,KAAK;AAC/B,cAAQ,WAAW,KAAK,GAAG;AAAA,IAC7B;AAAA,EACF,CAAC;AACH;;;AC9LA,IAAAC,YAA0B;AAC1B,IAAAC,YAA0B;AAC1B,aAAwB;AACxB,IAAAC,OAAqB;AACrB,IAAAC,QAAsB;AAUtB,IAAM,eAAe,CAAC,SAAS,SAAS,QAAQ,UAAU;AAExD,UAAa,UAAI,OAAO,QAAQ,GAAG,GAAG,KAAK;AAC3C,QAAM,kBAAkB,YAAY,SAAS,KAAK;AAElD,EAAS,uBAAa,QAAQ,aAAa,QAAQ,SAAS,eAAe;AAC3E,UAAQ,YAAY,MAAM;AAC1B,EAAS,uBAAa,QAAQ,aAAa,KAAK;AAChD,QAAM,cAAc,QAAQ;AAE5B,cAAY,MAAM,SAAS,QAAQ,YAAY,GAAG,KAAK;AACvD,WAAS,IAAI,kBAAkB,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACzD,YAAQ,GAAG,MAAM,SAAS,CAAC;AAAA,EAC7B;AACF;AAUO,IAAM,sBAAsB,CAAC,SAAS,OAAO,QAAQ;AAE1D,QAAM,KAAK,oBAAI,IAAI;AACnB,MAAI,QAAQ,CAAC,OAAO,WAAW;AAE7B,QAAI,SAAS,OAAO,MAAM,IAAI,OAAO;AACnC,SAAG,IAAI,QAAQ,KAAK;AAAA,IACtB;AAAA,EACF,CAAC;AACD,iBAAe,KAAK,EAAE,QAAQ,CAAC,OAAO,WAAW;AAC/C,QAAI,CAAC,IAAI,IAAI,MAAM,GAAG;AACpB,SAAG,IAAI,QAAQ,CAAC;AAAA,IAClB;AAAA,EACF,CAAC;AAED,EAAS,uBAAa,QAAQ,aAAa,GAAG,IAAI;AAGlD,QAAM,KAAK,GAAG,QAAQ,CAAC,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,KAAK,EAAE,EAAE,EAAE,QAAQ,CAAC,CAAC,QAAQ,KAAK,MAAM;AAEhF,iBAAa,SAAS,MAAM,QAAQ,IAAI,MAAM,GAAG,QAAQ,KAAK;AAAA,EAChE,CAAC;AACH;AA0QO,IAAM,8BAA8B,CAAC,SAAS,gBAAgB,oBAAoB,SAAS,YAAY,IAAI,OAAO,YAAY,WAAW;;;ACzWhJ,IAAAC,QAAsB;AACtB,YAAuB;AA6BhB,IAAM,iBAAiB,WAAS;AACrC,QAAM,KAAK,oBAAI,IAAI;AACnB,QAAM,QAAQ,QAAQ,CAAC,SAAS,WAAW;AACzC,UAAM,SAAS,QAAQ,QAAQ,SAAS;AACxC,OAAG,IAAI,QAAQ,OAAO,GAAG,QAAQ,OAAO,MAAM;AAAA,EAChD,CAAC;AACD,SAAO;AACT;AAUO,IAAM,WAAW,CAAC,OAAO,WAAW;AACzC,QAAM,UAAU,MAAM,QAAQ,IAAI,MAAM;AACxC,MAAI,YAAY,QAAW;AACzB,WAAO;AAAA,EACT;AACA,QAAM,aAAa,QAAQ,QAAQ,SAAS;AAC5C,SAAO,WAAW,GAAG,QAAQ,WAAW;AAC1C;AAkDO,IAAM,cAAc,CAAC,SAAS,UAAU;AAC7C,MAAI,OAAO;AACX,MAAI,QAAQ,QAAQ,SAAS;AAC7B,MAAI,MAAM,QAAQ;AAClB,MAAI,WAAW,IAAI,GAAG;AACtB,MAAI,aAAa,OAAO;AACtB,WAAO;AAAA,EACT;AAIA,MAAI,WAAgB,YAAO,SAAS,WAAW,IAAI,SAAS,KAAM,KAAK;AACvE,SAAO,QAAQ,OAAO;AACpB,UAAM,QAAQ;AACd,eAAW,IAAI,GAAG;AAClB,QAAI,YAAY,OAAO;AACrB,UAAI,QAAQ,WAAW,IAAI,QAAQ;AACjC,eAAO;AAAA,MACT;AACA,aAAO,WAAW;AAAA,IACpB,OAAO;AACL,cAAQ,WAAW;AAAA,IACrB;AACA,eAAgB,aAAO,OAAO,SAAS,CAAC;AAAA,EAC1C;AAGA,QAAY,qBAAe;AAC7B;;;AC3HA,IAAAC,OAAqB;AACrB,IAAAC,QAAsB;AACtB,UAAqB;AACrB,cAAyB;AACzB,sBAAwB;AAwGjB,IAAM,oCAAoC,CAAC,SAAS,gBAAgB;AACzE,MAAI,YAAY,UAAU,QAAQ,SAAS,KAAK,CAAK,SAAI,YAAY,YAAY,CAAC,OAAO,WAAW,YAAY,YAAY,IAAI,MAAM,MAAM,KAAK,GAAG;AAClJ,WAAO;AAAA,EACT;AACA,wBAAsB,YAAY,SAAS;AAC3C,8BAA4B,SAAS,WAAW;AAChD,iBAAe,SAAS,YAAY,SAAS;AAC7C,SAAO;AACT;;;AL3HA,IAAM,EAAE,MAAM,MAAM,IAAI;AAIxB,IAAM,SAAS,oBAAI,IAAmB;AACtC,IAAM,WAAW;AAEjB,IAAO,iCAAQ,0CAAwD,OAAO;AAAA,EAC1E,OAAO;AAAA,IACH,SAAS,CAAC;AAAA,IACV,WAAW;AAAA,MACP,cAAc;AAAA,QACV,aAAa,YAAY;AAAA,QAGzB;AAAA,MACJ;AAAA,IACJ;AAAA,IACA,eAAe;AAAA,MACX,aAAa;AAAA,QACT,oBAAoB,OAAO,EAAE,OAAO,MAAM,KAAK,gBAAgB,cAAc,MAAM;AAC/E,kBAAQ,IAAI,+CAA+C,KAAK,UAAU,OAAO,MAAM,CAAC,GAAG;AAE3F,cAAI,EAAE,KAAK,IAAI,MAAM,eAAe,QAAQ,UAAU,EAAE,OAAO,EAAE,MAAM,SAAS,EAAE,CAAC;AACnF,cAAI,WAAW,MAAM,cAAc;AAGnC,cAAI,CAAC,OAAO,IAAI,QAAQ,GAAG;AACvB,gBAAI;AAEJ,gBAAI,YAAY,MAAM;AAElB,sBAAQ,IAAM,OAAI;AAClB,oBAAM,QAAQ,MAAM,OAAO,MAAM;AACjC,oBAAM,EAAE,MAAAC,MAAK,IAAI,MAAM,eAAe,UAAU,WAAW;AAAA,gBACvD,OAAO;AAAA,kBACH,MAAM;AAAA,oBACF,MAAM;AAAA,oBACN,QAAQ,MAAM,SAAS,SAAS;AAAA,oBAChC,MAAM,MAAM;AAAA,oBACZ,WAAO,iCAAiB,uBAAoB,KAAK,CAAC;AAAA,oBAClD,YAAQ,iCAAiB,qBAAkB,KAAK,CAAC;AAAA,kBACrD;AAAA,gBACJ;AAAA,cACJ,CAAC;AACD,oBAAM,SAASA,OAAM;AACrB,kBAAI,UAAU,MAAM;AAChB,2BAAW;AAAA,cACf;AAAA,YACJ,OAAO;AAEH,sBAAQ,IAAM,OAAI,EAAE,MAAM,SAAS,KAAK,CAAC;AACzC,oBAAM,WAAW,SAAS,SAAS,MAAM;AACzC,oBAAM,QAAQ,MAAM,OAAO,MAAM;AACjC,cAAE,eAAY,WAAO,+BAAa,SAAS,KAAK,CAAC;AACjD,oBAAM,WAAW,SAAS,SAAS,MAAM;AAAA,YAC7C;AAEA,mBAAO,IAAI,UAAU,KAAK;AAE1B,kBAAM,GAAG,UAAU,CAAC,QAAQ,QAAQ,KAAK,gBAAgB;AACrD,sBAAQ,IAAI,wCAAwC,QAAQ,cAAU,iCAAe,MAAM,CAAC;AAAA,YAEhG,CAAC;AAAA,UACL;AAEA,cAAI,YAAY,MAAM;AAElB,kBAAM,iBAAiB,MAAM,eAAe,UAAU,aAAa;AAAA,cAC/D,OAAO;AAAA,gBACH,QAAQ;AAAA,kBACJ,SAAS,SAAS;AAAA,kBAClB,QAAQ,MAAM;AAAA,kBACd,MAAM,MAAM;AAAA,kBACZ,QAAQ,MAAM;AAAA,gBAClB;AAAA,cACJ;AAAA,YACJ,CAAC;AAAA,UACL;AAEA,iBAAO;AAAA,QACX;AAAA,QACA,qBAAqB,OAAO,EAAE,OAAO,MAAM,eAAe,KAAK,UAAU,eAAe,MAAM;AAC1F,kBAAQ;AAAA,YACJ,wDAAwD,KAAK,UAAU,OAAO,MAAM,CAAC;AAAA,UACzF;AACA,cAAI,SAAS,QAAQ,MAAM;AACvB,kBAAM,IAAI,MAAM,8BAA8B;AAAA,UAClD;AAEA,gBAAM,QAAQ,OAAO,IAAI,QAAQ;AACjC,cAAI,SAAS,MAAM;AACf,kBAAM,IAAI,MAAM,oDAAoD;AAAA,UACxE;AACA,gBAAM,WAAW,MAAM,OAAO,MAAM;AAEpC,kBAAQ,IAAI,sCAAsC;AAClD,gBAAM,YAAY,MAAM,eAAe,QAAQ,YAAY;AAAA,YACvD,OAAO,EAAE,QAAQ,MAAM,UAAU,MAAM,SAAS;AAAA,UACpD,CAAC;AACD,kBAAQ,IAAI,aAAa,SAAS;AAElC,gBAAM,SAAS,WAAW,MAAM,eAAe;AAC/C,kBAAQ,IAAI,8BAA8B,MAAM;AAChD,cAAI,UAAU,MAAM;AAChB,kBAAM,IAAI,MAAM,uBAAuB;AAAA,UAC3C;AAEA,cAAI;AAEJ,gBAAM,aAAa,QAAQ,OAAO;AAClC,gBAAM,eAAe,MAAM,SAAS,OAAO,GAAG,SAAS,IAAI;AAC3D,gBAAM,WAAW,QAAQ,OAAO,UAAU;AAC1C,kBAAQ,IAAI,cAAe,SAAS,KAAK,KAAS,WAAW,KAAK,UAAU,cAAc,MAAM,CAAC,CAAC;AAClG,kBAAQ,IAAI,6BAA6B,OAAO,MAAM;AAEtD,gBAAM,gBAAgB,QAAQ,OAAO;AACrC,cAAI,IAA0B;AAE9B,gBAAM,SAAS,CAAC,OAAO;AACnB,uBAAW,UAAU,SAAU,IAAK;AACpC,oBAAI,yBAAU,EAAE;AAAA,UACpB,CAAC;AAED,cAAI,KAAK,MAAM;AACX,kBAAM,IAAI,MAAM,kBAAkB;AAAA,UACtC;AAEA,gBAAM,UAAU,IAAM,mBAAgB;AACtC,gBAAM,aAAa,kCAAkC,SAAS,CAAC;AAC/D,kBAAQ,IAAI,sBAAsB,gBAAY,iCAAe,QAAQ,aAAa,CAAC,CAAC;AAEpF,gBAAM,cAAc,QAAQ,OAAO,aAAa;AAEhD,cAAI,CAAC,YAAY;AAEb,mBAAO,EAAE,MAAM,CAAC,EAAE;AAAA,UACtB;AAEA,iBAAS,uBAAoB,WAAO,+BAAa,OAAO,MAAM,CAAC;AAC/D,kBAAQ,IAAI,6BAA6B,YAAY,KAAK,KAAS,yBAAyB,MAAM,SAAS,SAAS,CAAC;AAErH,gBAAM,eAAe,MAAM,eAAe,UAAU,WAAW;AAAA,YAC3D,OAAO;AAAA,cACH,QAAQ,MAAM,SAAS,SAAS;AAAA,cAChC,MAAM;AAAA,gBACF,WAAO,iCAAiB,uBAAoB,KAAK,CAAC;AAAA,gBAClD,YAAQ,iCAAiB,qBAAkB,KAAK,CAAC;AAAA,cACrD;AAAA,YACJ;AAAA,UACJ,CAAC;AAUD,gBAAM,iBAAiB,MAAM,eAAe,UAAU,aAAa;AAAA,YAC/D,OAAO;AAAA,cACH,QAAQ;AAAA,gBACJ,QAAQ,MAAM;AAAA,gBACd,MAAM,MAAM;AAAA,gBACZ,YAAQ,iCAAiB,qBAAkB,KAAK,CAAC;AAAA,cACrD;AAAA,YACJ;AAAA,UACJ,CAAC;AAOD,kBAAQ,IAAI,oCAAoC;AAEhD,iBAAO,EAAE,UAAM,iCAAe,IAAI,EAAE;AAAA,QACxC;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA,gBAAgB;AAAA,IACZ;AAAA,MACI,cAAc;AAAA,MACd,YAAY;AAAA,MACZ,uBAAuB;AAAA,MACvB,QAAQ,IAAI,6BAAc;AAAA,QACtB,OAAO,IAAI,iCAAgD;AAAA,UACvD,MAAM;AAAA,UACN,QAAQ;AAAA,YACJ,OAAO;AAAA,cACH,MAAM;AAAA,cACN,SAAS,CAAC,MAAW,QAAiC;AAClD,uBAAO,SAAS,IAAI,YAAY,MAAM,QAAQ;AAAA,cAClD;AAAA,YACJ;AAAA,UACJ;AAAA,QACJ,CAAC;AAAA,QACD,cAAc,IAAI,iCAAgD;AAAA,UAC9D,MAAM;AAAA,UACN,QAAQ;AAAA,YACJ,OAAO;AAAA,cACH,MAAM;AAAA,cACN,SAAS,CAAC,MAAW,QAAiC;AAClD,uBAAO,SAAS,IAAI,YAAY,MAAM,QAAQ;AAAA,cAClD;AAAA,YACJ;AAAA,UACJ;AAAA,QACJ,CAAC;AAAA,MACL,CAAC;AAAA,IACL;AAAA,EACJ;AACJ,EAAE;;;AF1NF,IAAM,SAAS,uBAAW,QAAQ;AAAA,EAC9B,cAAc;AAAA,EACd,KAAK,IAAI,gCAAoB,yBAAyB;AAAA,EACtD,SAAS,CAAC,YACN,QAAQ,gBAAgB,yBAAyB,IAAI,gCAAoB,6BAA6B,CAAC;AAC/G,CAAC;AAAA,IAGD,6CAAgC;AAAA,EAC5B,MAAM,CAAC,MAAM;AAAA,EACb;AAAA,EACA;AAAA,EACA,gBAAgB;AAAA,IACZ;AAAA,MACI,WAAW,CAAC,GAAG,sBAAU,WAAW,GAAG;AAAA,IAC3C;AAAA,IACA;AAAA,MACI,WAAW,CAAC,sBAAU,WAAW,MAAM;AAAA,MACvC,MAAM;AAAA,IACV;AAAA,EACJ;AAAA,EACA,MAAM;AAAA,IACF,GAAG,iBAAK;AAAA,IACR,gBAAgB,CAAC,GAAG;AAAA,EAExB;AAAA,EACA,kBAAkB;AAAA,IACd,4BAA4B;AAAA,EAChC;AAAA,EACA,UAAU;AAAA,IACN,uBAAuB;AAAA,EAC3B;AACJ,CAAC;",
  "names": ["module", "module", "module", "key", "module", "module", "doc", "meta", "module", "import_sdk", "Y", "targetValue", "managedType", "map", "encoding", "decoding", "map", "math", "math", "map", "math", "data"]
}
